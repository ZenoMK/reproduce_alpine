[2025-02-22 23:16:06,073][INFO] step 0: train loss 4.6263, val loss 4.6264
[2025-02-22 23:16:06,683][INFO] iter 0: loss 4.6239
[2025-02-22 23:16:11,305][INFO] iter 100: loss 3.2801
[2025-02-22 23:16:15,852][INFO] iter 200: loss 1.8233
[2025-02-22 23:16:20,735][INFO] iter 300: loss 0.9006
[2025-02-22 23:16:25,235][INFO] iter 400: loss 0.6528
[2025-02-22 23:16:30,099][INFO] iter 500: loss 0.6043
[2025-02-22 23:16:34,651][INFO] iter 600: loss 0.5980
[2025-02-22 23:16:39,169][INFO] iter 700: loss 0.5983
[2025-02-22 23:16:44,114][INFO] iter 800: loss 0.5850
[2025-02-22 23:16:48,652][INFO] iter 900: loss 0.5974
[2025-02-22 23:17:52,539][INFO] step 1000: train loss 0.5935, val loss 0.5949
[2025-02-22 23:17:52,540][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:17:52,858][INFO] iter 1000: loss 0.5940
[2025-02-22 23:17:57,519][INFO] iter 1100: loss 0.5909
[2025-02-22 23:18:02,094][INFO] iter 1200: loss 0.5937
[2025-02-22 23:18:07,029][INFO] iter 1300: loss 0.5997
[2025-02-22 23:18:11,762][INFO] iter 1400: loss 0.5980
[2025-02-22 23:18:16,370][INFO] iter 1500: loss 0.5879
[2025-02-22 23:18:21,168][INFO] iter 1600: loss 0.5934
[2025-02-22 23:18:25,799][INFO] iter 1700: loss 0.6040
[2025-02-22 23:18:30,738][INFO] iter 1800: loss 0.5961
[2025-02-22 23:18:35,390][INFO] iter 1900: loss 0.5865
[2025-02-22 23:19:39,682][INFO] step 2000: train loss 0.5912, val loss 0.5898
[2025-02-22 23:19:39,683][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:19:39,822][INFO] iter 2000: loss 0.5812
[2025-02-22 23:19:44,537][INFO] iter 2100: loss 0.5941
[2025-02-22 23:19:49,201][INFO] iter 2200: loss 0.5883
[2025-02-22 23:19:54,097][INFO] iter 2300: loss 0.5985
[2025-02-22 23:19:58,789][INFO] iter 2400: loss 0.5858
[2025-02-22 23:20:03,751][INFO] iter 2500: loss 0.5887
[2025-02-22 23:20:08,466][INFO] iter 2600: loss 0.6010
[2025-02-22 23:20:13,192][INFO] iter 2700: loss 0.5902
[2025-02-22 23:20:18,358][INFO] iter 2800: loss 0.5821
[2025-02-22 23:20:23,101][INFO] iter 2900: loss 0.5930
[2025-02-22 23:21:27,228][INFO] step 3000: train loss 0.5899, val loss 0.5903
[2025-02-22 23:21:27,228][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:21:27,333][INFO] iter 3000: loss 0.5903
[2025-02-22 23:21:32,056][INFO] iter 3100: loss 0.5920
[2025-02-22 23:21:36,706][INFO] iter 3200: loss 0.5924
[2025-02-22 23:21:41,852][INFO] iter 3300: loss 0.5858
[2025-02-22 23:21:46,612][INFO] iter 3400: loss 0.5881
[2025-02-22 23:21:51,549][INFO] iter 3500: loss 0.5878
[2025-02-22 23:21:56,262][INFO] iter 3600: loss 0.5962
[2025-02-22 23:22:01,070][INFO] iter 3700: loss 0.5826
[2025-02-22 23:22:06,029][INFO] iter 3800: loss 0.5981
[2025-02-22 23:22:10,771][INFO] iter 3900: loss 0.6012
[2025-02-22 23:23:14,996][INFO] step 4000: train loss 0.5895, val loss 0.5892
[2025-02-22 23:23:14,997][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:23:15,104][INFO] iter 4000: loss 0.5814
[2025-02-22 23:23:19,791][INFO] iter 4100: loss 0.5909
[2025-02-22 23:23:24,448][INFO] iter 4200: loss 0.5774
[2025-02-22 23:23:29,446][INFO] iter 4300: loss 0.5812
[2025-02-22 23:23:34,134][INFO] iter 4400: loss 0.5926
[2025-02-22 23:23:39,116][INFO] iter 4500: loss 0.5918
[2025-02-22 23:23:43,826][INFO] iter 4600: loss 0.5834
[2025-02-22 23:23:48,556][INFO] iter 4700: loss 0.5932
[2025-02-22 23:23:53,407][INFO] iter 4800: loss 0.5953
[2025-02-22 23:23:58,149][INFO] iter 4900: loss 0.5918
[2025-02-22 23:25:02,547][INFO] step 5000: train loss 0.5891, val loss 0.5893
[2025-02-22 23:25:02,547][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:25:02,655][INFO] iter 5000: loss 0.5883
[2025-02-22 23:25:07,354][INFO] iter 5100: loss 0.5848
[2025-02-22 23:25:12,295][INFO] iter 5200: loss 0.5849
[2025-02-22 23:25:16,963][INFO] iter 5300: loss 0.5822
[2025-02-22 23:25:21,648][INFO] iter 5400: loss 0.5923
[2025-02-22 23:25:26,649][INFO] iter 5500: loss 0.5858
[2025-02-22 23:25:31,362][INFO] iter 5600: loss 0.5930
[2025-02-22 23:25:36,333][INFO] iter 5700: loss 0.5850
[2025-02-22 23:25:41,068][INFO] iter 5800: loss 0.5953
[2025-02-22 23:25:45,804][INFO] iter 5900: loss 0.5833
[2025-02-22 23:26:50,572][INFO] step 6000: train loss 0.5888, val loss 0.5892
[2025-02-22 23:26:50,573][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:26:50,681][INFO] iter 6000: loss 0.6026
[2025-02-22 23:26:55,380][INFO] iter 6100: loss 0.5887
[2025-02-22 23:27:00,294][INFO] iter 6200: loss 0.5899
[2025-02-22 23:27:05,031][INFO] iter 6300: loss 0.5831
[2025-02-22 23:27:09,720][INFO] iter 6400: loss 0.5856
[2025-02-22 23:27:14,602][INFO] iter 6500: loss 0.5895
[2025-02-22 23:27:19,406][INFO] iter 6600: loss 0.5932
[2025-02-22 23:27:24,372][INFO] iter 6700: loss 0.5860
[2025-02-22 23:27:29,105][INFO] iter 6800: loss 0.5887
[2025-02-22 23:27:34,106][INFO] iter 6900: loss 0.5859
[2025-02-22 23:28:38,331][INFO] step 7000: train loss 0.5881, val loss 0.5880
[2025-02-22 23:28:38,331][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:28:38,439][INFO] iter 7000: loss 0.5920
[2025-02-22 23:28:43,125][INFO] iter 7100: loss 0.5975
[2025-02-22 23:28:48,089][INFO] iter 7200: loss 0.5776
[2025-02-22 23:28:52,762][INFO] iter 7300: loss 0.5933
[2025-02-22 23:28:57,552][INFO] iter 7400: loss 0.5926
[2025-02-22 23:29:02,402][INFO] iter 7500: loss 0.5875
[2025-02-22 23:29:07,117][INFO] iter 7600: loss 0.5910
[2025-02-22 23:29:12,291][INFO] iter 7700: loss 0.5833
[2025-02-22 23:29:17,032][INFO] iter 7800: loss 0.5905
[2025-02-22 23:29:21,982][INFO] iter 7900: loss 0.5909
[2025-02-22 23:30:26,389][INFO] step 8000: train loss 0.5884, val loss 0.5881
[2025-02-22 23:30:26,389][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:30:26,497][INFO] iter 8000: loss 0.5859
[2025-02-22 23:30:31,184][INFO] iter 8100: loss 0.5899
[2025-02-22 23:30:36,053][INFO] iter 8200: loss 0.5920
[2025-02-22 23:30:40,735][INFO] iter 8300: loss 0.5987
[2025-02-22 23:30:45,683][INFO] iter 8400: loss 0.5945
[2025-02-22 23:30:50,382][INFO] iter 8500: loss 0.6010
[2025-02-22 23:30:55,218][INFO] iter 8600: loss 0.5881
[2025-02-22 23:31:00,128][INFO] iter 8700: loss 0.5902
[2025-02-22 23:31:04,873][INFO] iter 8800: loss 0.5860
[2025-02-22 23:31:09,994][INFO] iter 8900: loss 0.5918
[2025-02-22 23:32:15,475][INFO] step 9000: train loss 0.5880, val loss 0.5880
[2025-02-22 23:32:15,476][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:32:15,585][INFO] iter 9000: loss 0.5923
[2025-02-22 23:32:20,696][INFO] iter 9100: loss 0.5800
[2025-02-22 23:32:25,480][INFO] iter 9200: loss 0.5847
[2025-02-22 23:32:30,158][INFO] iter 9300: loss 0.5820
[2025-02-22 23:32:35,141][INFO] iter 9400: loss 0.5854
[2025-02-22 23:32:39,949][INFO] iter 9500: loss 0.5957
[2025-02-22 23:32:45,058][INFO] iter 9600: loss 0.5881
[2025-02-22 23:32:49,791][INFO] iter 9700: loss 0.5832
[2025-02-22 23:32:54,888][INFO] iter 9800: loss 0.5966
[2025-02-22 23:32:59,724][INFO] iter 9900: loss 0.5881
[2025-02-22 23:34:05,824][INFO] step 10000: train loss 0.5878, val loss 0.5875
[2025-02-22 23:34:05,824][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-22 23:34:05,952][INFO] iter 10000: loss 0.5740
