[2025-02-23 15:49:35,373][INFO] step 0: train loss 4.6013, val loss 4.6015
[2025-02-23 15:49:38,840][INFO] iter 0: loss 4.6005
[2025-02-23 15:49:43,707][INFO] iter 100: loss 3.1915
[2025-02-23 15:49:48,818][INFO] iter 200: loss 1.7487
[2025-02-23 15:49:53,467][INFO] iter 300: loss 0.8647
[2025-02-23 15:49:58,835][INFO] iter 400: loss 0.6302
[2025-02-23 15:50:03,638][INFO] iter 500: loss 0.5865
[2025-02-23 15:50:08,842][INFO] iter 600: loss 0.5774
[2025-02-23 15:50:13,659][INFO] iter 700: loss 0.5743
[2025-02-23 15:50:18,364][INFO] iter 800: loss 0.5742
[2025-02-23 15:50:23,672][INFO] iter 900: loss 0.5742
[2025-02-23 15:51:31,170][INFO] step 1000: train loss 0.5726, val loss 0.5724
[2025-02-23 15:51:31,171][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 15:51:31,280][INFO] iter 1000: loss 0.5811
[2025-02-23 15:51:36,512][INFO] iter 1100: loss 0.5717
[2025-02-23 15:51:41,275][INFO] iter 1200: loss 0.5761
[2025-02-23 15:51:46,245][INFO] iter 1300: loss 0.5705
[2025-02-23 15:51:51,061][INFO] iter 1400: loss 0.5682
[2025-02-23 15:51:55,777][INFO] iter 1500: loss 0.5754
[2025-02-23 15:52:01,089][INFO] iter 1600: loss 0.5709
[2025-02-23 15:52:05,836][INFO] iter 1700: loss 0.5752
[2025-02-23 15:52:10,981][INFO] iter 1800: loss 0.5703
[2025-02-23 15:52:15,730][INFO] iter 1900: loss 0.5670
[2025-02-23 15:53:23,355][INFO] step 2000: train loss 0.5701, val loss 0.5700
[2025-02-23 15:53:23,355][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 15:53:23,463][INFO] iter 2000: loss 0.5709
[2025-02-23 15:53:28,209][INFO] iter 2100: loss 0.5736
[2025-02-23 15:53:32,935][INFO] iter 2200: loss 0.5622
[2025-02-23 15:53:38,226][INFO] iter 2300: loss 0.5669
[2025-02-23 15:53:42,953][INFO] iter 2400: loss 0.5766
[2025-02-23 15:53:48,181][INFO] iter 2500: loss 0.5604
[2025-02-23 15:53:52,930][INFO] iter 2600: loss 0.5716
[2025-02-23 15:53:57,994][INFO] iter 2700: loss 0.5696
[2025-02-23 15:54:02,928][INFO] iter 2800: loss 0.5672
[2025-02-23 15:54:07,698][INFO] iter 2900: loss 0.5639
[2025-02-23 15:55:14,910][INFO] step 3000: train loss 0.5693, val loss 0.5701
[2025-02-23 15:55:14,911][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 15:55:15,017][INFO] iter 3000: loss 0.5724
[2025-02-23 15:55:19,766][INFO] iter 3100: loss 0.5598
[2025-02-23 15:55:25,068][INFO] iter 3200: loss 0.5710
[2025-02-23 15:55:29,822][INFO] iter 3300: loss 0.5636
[2025-02-23 15:55:34,952][INFO] iter 3400: loss 0.5722
[2025-02-23 15:55:39,703][INFO] iter 3500: loss 0.5707
[2025-02-23 15:55:44,458][INFO] iter 3600: loss 0.5726
[2025-02-23 15:55:49,864][INFO] iter 3700: loss 0.5682
[2025-02-23 15:55:54,808][INFO] iter 3800: loss 0.5739
[2025-02-23 15:55:59,944][INFO] iter 3900: loss 0.5724
[2025-02-23 15:57:06,545][INFO] step 4000: train loss 0.5688, val loss 0.5685
[2025-02-23 15:57:06,545][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 15:57:06,651][INFO] iter 4000: loss 0.5675
[2025-02-23 15:57:11,779][INFO] iter 4100: loss 0.5685
[2025-02-23 15:57:16,509][INFO] iter 4200: loss 0.5745
[2025-02-23 15:57:21,312][INFO] iter 4300: loss 0.5746
[2025-02-23 15:57:26,507][INFO] iter 4400: loss 0.5617
[2025-02-23 15:57:31,262][INFO] iter 4500: loss 0.5684
[2025-02-23 15:57:36,595][INFO] iter 4600: loss 0.5710
[2025-02-23 15:57:41,371][INFO] iter 4700: loss 0.5638
[2025-02-23 15:57:46,654][INFO] iter 4800: loss 0.5742
[2025-02-23 15:57:51,425][INFO] iter 4900: loss 0.5710
[2025-02-23 15:58:58,683][INFO] step 5000: train loss 0.5683, val loss 0.5683
[2025-02-23 15:58:58,684][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 15:58:58,791][INFO] iter 5000: loss 0.5674
[2025-02-23 15:59:03,720][INFO] iter 5100: loss 0.5704
[2025-02-23 15:59:08,451][INFO] iter 5200: loss 0.5673
[2025-02-23 15:59:13,810][INFO] iter 5300: loss 0.5651
[2025-02-23 15:59:18,565][INFO] iter 5400: loss 0.5729
[2025-02-23 15:59:23,868][INFO] iter 5500: loss 0.5753
[2025-02-23 15:59:28,634][INFO] iter 5600: loss 0.5590
[2025-02-23 15:59:33,399][INFO] iter 5700: loss 0.5598
[2025-02-23 15:59:38,659][INFO] iter 5800: loss 0.5682
[2025-02-23 15:59:43,590][INFO] iter 5900: loss 0.5674
[2025-02-23 16:00:50,132][INFO] step 6000: train loss 0.5679, val loss 0.5686
[2025-02-23 16:00:50,133][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 16:00:50,238][INFO] iter 6000: loss 0.5697
[2025-02-23 16:00:55,028][INFO] iter 6100: loss 0.5672
[2025-02-23 16:01:00,108][INFO] iter 6200: loss 0.5591
[2025-02-23 16:01:04,853][INFO] iter 6300: loss 0.5593
[2025-02-23 16:01:09,600][INFO] iter 6400: loss 0.5753
[2025-02-23 16:01:14,738][INFO] iter 6500: loss 0.5692
[2025-02-23 16:01:19,505][INFO] iter 6600: loss 0.5712
[2025-02-23 16:01:24,705][INFO] iter 6700: loss 0.5676
[2025-02-23 16:01:29,482][INFO] iter 6800: loss 0.5746
[2025-02-23 16:01:34,697][INFO] iter 6900: loss 0.5668
[2025-02-23 16:02:40,930][INFO] step 7000: train loss 0.5676, val loss 0.5681
[2025-02-23 16:02:40,930][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 16:02:41,035][INFO] iter 7000: loss 0.5633
[2025-02-23 16:02:45,811][INFO] iter 7100: loss 0.5656
[2025-02-23 16:02:50,904][INFO] iter 7200: loss 0.5683
[2025-02-23 16:02:55,641][INFO] iter 7300: loss 0.5770
[2025-02-23 16:03:00,855][INFO] iter 7400: loss 0.5698
[2025-02-23 16:03:05,625][INFO] iter 7500: loss 0.5669
[2025-02-23 16:03:10,883][INFO] iter 7600: loss 0.5681
[2025-02-23 16:03:15,648][INFO] iter 7700: loss 0.5786
[2025-02-23 16:03:20,408][INFO] iter 7800: loss 0.5713
[2025-02-23 16:03:25,795][INFO] iter 7900: loss 0.5663
[2025-02-23 16:04:32,255][INFO] step 8000: train loss 0.5668, val loss 0.5660
[2025-02-23 16:04:32,256][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 16:04:32,362][INFO] iter 8000: loss 0.5675
[2025-02-23 16:04:37,681][INFO] iter 8100: loss 0.5706
[2025-02-23 16:04:42,436][INFO] iter 8200: loss 0.5692
[2025-02-23 16:04:47,576][INFO] iter 8300: loss 0.5611
[2025-02-23 16:04:52,317][INFO] iter 8400: loss 0.5709
[2025-02-23 16:04:57,069][INFO] iter 8500: loss 0.5627
[2025-02-23 16:05:02,343][INFO] iter 8600: loss 0.5779
[2025-02-23 16:05:07,260][INFO] iter 8700: loss 0.5641
[2025-02-23 16:05:12,476][INFO] iter 8800: loss 0.5632
[2025-02-23 16:05:17,262][INFO] iter 8900: loss 0.5686
[2025-02-23 16:06:23,916][INFO] step 9000: train loss 0.5675, val loss 0.5676
[2025-02-23 16:06:23,917][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 16:06:24,025][INFO] iter 9000: loss 0.5662
[2025-02-23 16:06:28,785][INFO] iter 9100: loss 0.5723
[2025-02-23 16:06:33,506][INFO] iter 9200: loss 0.5664
[2025-02-23 16:06:38,667][INFO] iter 9300: loss 0.5592
[2025-02-23 16:06:43,407][INFO] iter 9400: loss 0.5675
[2025-02-23 16:06:48,633][INFO] iter 9500: loss 0.5633
[2025-02-23 16:06:53,383][INFO] iter 9600: loss 0.5652
[2025-02-23 16:06:58,567][INFO] iter 9700: loss 0.5632
[2025-02-23 16:07:03,331][INFO] iter 9800: loss 0.5673
[2025-02-23 16:07:08,106][INFO] iter 9900: loss 0.5585
[2025-02-23 16:08:14,970][INFO] step 10000: train loss 0.5671, val loss 0.5668
[2025-02-23 16:08:14,970][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 16:08:15,078][INFO] iter 10000: loss 0.5645
