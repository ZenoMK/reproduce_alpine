[2025-02-23 02:26:57,695][INFO] step 0: train loss 4.6605, val loss 4.6601
[2025-02-23 02:27:00,832][INFO] iter 0: loss 4.6609
[2025-02-23 02:27:05,636][INFO] iter 100: loss 3.2947
[2025-02-23 02:27:10,652][INFO] iter 200: loss 1.8279
[2025-02-23 02:27:15,390][INFO] iter 300: loss 0.8655
[2025-02-23 02:27:20,223][INFO] iter 400: loss 0.6229
[2025-02-23 02:27:25,230][INFO] iter 500: loss 0.5879
[2025-02-23 02:27:30,030][INFO] iter 600: loss 0.5748
[2025-02-23 02:27:35,064][INFO] iter 700: loss 0.5696
[2025-02-23 02:27:40,005][INFO] iter 800: loss 0.5594
[2025-02-23 02:27:44,838][INFO] iter 900: loss 0.5699
[2025-02-23 02:28:49,105][INFO] step 1000: train loss 0.5660, val loss 0.5661
[2025-02-23 02:28:49,106][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:28:49,217][INFO] iter 1000: loss 0.5530
[2025-02-23 02:28:54,004][INFO] iter 1100: loss 0.5728
[2025-02-23 02:28:59,041][INFO] iter 1200: loss 0.5746
[2025-02-23 02:29:03,846][INFO] iter 1300: loss 0.5670
[2025-02-23 02:29:08,680][INFO] iter 1400: loss 0.5528
[2025-02-23 02:29:14,037][INFO] iter 1500: loss 0.5562
[2025-02-23 02:29:18,881][INFO] iter 1600: loss 0.5631
[2025-02-23 02:29:23,992][INFO] iter 1700: loss 0.5660
[2025-02-23 02:29:28,787][INFO] iter 1800: loss 0.5692
[2025-02-23 02:29:33,560][INFO] iter 1900: loss 0.5637
[2025-02-23 02:30:37,339][INFO] step 2000: train loss 0.5635, val loss 0.5640
[2025-02-23 02:30:37,340][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:30:37,444][INFO] iter 2000: loss 0.5590
[2025-02-23 02:30:42,244][INFO] iter 2100: loss 0.5614
[2025-02-23 02:30:47,179][INFO] iter 2200: loss 0.5625
[2025-02-23 02:30:51,988][INFO] iter 2300: loss 0.5677
[2025-02-23 02:30:56,817][INFO] iter 2400: loss 0.5673
[2025-02-23 02:31:01,881][INFO] iter 2500: loss 0.5650
[2025-02-23 02:31:06,847][INFO] iter 2600: loss 0.5637
[2025-02-23 02:31:11,907][INFO] iter 2700: loss 0.5579
[2025-02-23 02:31:16,697][INFO] iter 2800: loss 0.5535
[2025-02-23 02:31:21,704][INFO] iter 2900: loss 0.5547
[2025-02-23 02:32:25,132][INFO] step 3000: train loss 0.5623, val loss 0.5625
[2025-02-23 02:32:25,133][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:32:25,239][INFO] iter 3000: loss 0.5632
[2025-02-23 02:32:30,033][INFO] iter 3100: loss 0.5540
[2025-02-23 02:32:35,104][INFO] iter 3200: loss 0.5698
[2025-02-23 02:32:39,982][INFO] iter 3300: loss 0.5735
[2025-02-23 02:32:45,040][INFO] iter 3400: loss 0.5542
[2025-02-23 02:32:49,875][INFO] iter 3500: loss 0.5638
[2025-02-23 02:32:54,691][INFO] iter 3600: loss 0.5699
[2025-02-23 02:32:59,803][INFO] iter 3700: loss 0.5588
[2025-02-23 02:33:04,580][INFO] iter 3800: loss 0.5600
[2025-02-23 02:33:09,430][INFO] iter 3900: loss 0.5689
[2025-02-23 02:34:13,090][INFO] step 4000: train loss 0.5617, val loss 0.5623
[2025-02-23 02:34:13,091][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:34:13,197][INFO] iter 4000: loss 0.5681
[2025-02-23 02:34:17,983][INFO] iter 4100: loss 0.5648
[2025-02-23 02:34:23,048][INFO] iter 4200: loss 0.5624
[2025-02-23 02:34:27,842][INFO] iter 4300: loss 0.5542
[2025-02-23 02:34:32,835][INFO] iter 4400: loss 0.5528
[2025-02-23 02:34:37,678][INFO] iter 4500: loss 0.5613
[2025-02-23 02:34:42,524][INFO] iter 4600: loss 0.5574
[2025-02-23 02:34:47,680][INFO] iter 4700: loss 0.5628
[2025-02-23 02:34:52,480][INFO] iter 4800: loss 0.5644
[2025-02-23 02:34:57,502][INFO] iter 4900: loss 0.5648
[2025-02-23 02:36:00,847][INFO] step 5000: train loss 0.5605, val loss 0.5608
[2025-02-23 02:36:00,847][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:36:00,953][INFO] iter 5000: loss 0.5645
[2025-02-23 02:36:05,953][INFO] iter 5100: loss 0.5491
[2025-02-23 02:36:10,844][INFO] iter 5200: loss 0.5593
[2025-02-23 02:36:15,639][INFO] iter 5300: loss 0.5596
[2025-02-23 02:36:20,734][INFO] iter 5400: loss 0.5640
[2025-02-23 02:36:25,554][INFO] iter 5500: loss 0.5542
[2025-02-23 02:36:30,414][INFO] iter 5600: loss 0.5651
[2025-02-23 02:36:35,234][INFO] iter 5700: loss 0.5699
[2025-02-23 02:36:40,172][INFO] iter 5800: loss 0.5540
[2025-02-23 02:36:45,261][INFO] iter 5900: loss 0.5611
[2025-02-23 02:37:48,947][INFO] step 6000: train loss 0.5607, val loss 0.5595
[2025-02-23 02:37:48,947][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:37:49,053][INFO] iter 6000: loss 0.5597
[2025-02-23 02:37:54,067][INFO] iter 6100: loss 0.5705
[2025-02-23 02:37:58,828][INFO] iter 6200: loss 0.5544
[2025-02-23 02:38:03,609][INFO] iter 6300: loss 0.5502
[2025-02-23 02:38:08,898][INFO] iter 6400: loss 0.5649
[2025-02-23 02:38:13,816][INFO] iter 6500: loss 0.5648
[2025-02-23 02:38:18,848][INFO] iter 6600: loss 0.5539
[2025-02-23 02:38:23,672][INFO] iter 6700: loss 0.5659
[2025-02-23 02:38:28,570][INFO] iter 6800: loss 0.5556
[2025-02-23 02:38:33,506][INFO] iter 6900: loss 0.5613
[2025-02-23 02:39:37,217][INFO] step 7000: train loss 0.5606, val loss 0.5602
[2025-02-23 02:39:37,218][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:39:37,324][INFO] iter 7000: loss 0.5537
[2025-02-23 02:39:42,415][INFO] iter 7100: loss 0.5483
[2025-02-23 02:39:47,225][INFO] iter 7200: loss 0.5623
[2025-02-23 02:39:52,121][INFO] iter 7300: loss 0.5634
[2025-02-23 02:39:57,024][INFO] iter 7400: loss 0.5562
[2025-02-23 02:40:01,855][INFO] iter 7500: loss 0.5568
[2025-02-23 02:40:06,901][INFO] iter 7600: loss 0.5594
[2025-02-23 02:40:11,743][INFO] iter 7700: loss 0.5648
[2025-02-23 02:40:16,601][INFO] iter 7800: loss 0.5596
[2025-02-23 02:40:21,466][INFO] iter 7900: loss 0.5577
[2025-02-23 02:41:25,147][INFO] step 8000: train loss 0.5604, val loss 0.5596
[2025-02-23 02:41:25,148][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:41:25,253][INFO] iter 8000: loss 0.5640
[2025-02-23 02:41:30,327][INFO] iter 8100: loss 0.5569
[2025-02-23 02:41:35,113][INFO] iter 8200: loss 0.5640
[2025-02-23 02:41:40,261][INFO] iter 8300: loss 0.5571
[2025-02-23 02:41:45,097][INFO] iter 8400: loss 0.5474
[2025-02-23 02:41:49,944][INFO] iter 8500: loss 0.5645
[2025-02-23 02:41:55,144][INFO] iter 8600: loss 0.5560
[2025-02-23 02:41:59,953][INFO] iter 8700: loss 0.5592
[2025-02-23 02:42:04,976][INFO] iter 8800: loss 0.5542
[2025-02-23 02:42:09,731][INFO] iter 8900: loss 0.5636
[2025-02-23 02:43:13,214][INFO] step 9000: train loss 0.5601, val loss 0.5605
[2025-02-23 02:43:13,215][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:43:13,346][INFO] iter 9000: loss 0.5678
[2025-02-23 02:43:18,289][INFO] iter 9100: loss 0.5496
[2025-02-23 02:43:23,075][INFO] iter 9200: loss 0.5564
[2025-02-23 02:43:28,173][INFO] iter 9300: loss 0.5604
[2025-02-23 02:43:33,013][INFO] iter 9400: loss 0.5610
[2025-02-23 02:43:37,862][INFO] iter 9500: loss 0.5621
[2025-02-23 02:43:42,777][INFO] iter 9600: loss 0.5453
[2025-02-23 02:43:47,701][INFO] iter 9700: loss 0.5586
[2025-02-23 02:43:52,687][INFO] iter 9800: loss 0.5614
[2025-02-23 02:43:57,450][INFO] iter 9900: loss 0.5613
[2025-02-23 02:45:00,616][INFO] step 10000: train loss 0.5601, val loss 0.5593
[2025-02-23 02:45:00,617][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 02:45:00,744][INFO] iter 10000: loss 0.5653
