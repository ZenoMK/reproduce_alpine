[2025-02-22 16:36:57,064][INFO] step 0: train loss 6.2527, val loss 6.2673
[2025-02-22 16:37:00,199][INFO] iter 0: loss 6.2521
[2025-02-22 16:37:05,807][INFO] iter 100: loss 4.6221
[2025-02-22 16:37:10,963][INFO] iter 200: loss 3.0226
[2025-02-22 16:37:16,270][INFO] iter 300: loss 1.7078
[2025-02-22 16:37:21,354][INFO] iter 400: loss 1.2316
[2025-02-22 16:37:26,513][INFO] iter 500: loss 1.0592
[2025-02-22 16:37:31,712][INFO] iter 600: loss 0.9722
[2025-02-22 16:37:36,820][INFO] iter 700: loss 0.9745
[2025-02-22 16:37:42,241][INFO] iter 800: loss 0.9405
[2025-02-22 16:37:47,369][INFO] iter 900: loss 0.9346
[2025-02-22 16:38:55,235][INFO] step 1000: train loss 0.9279, val loss 1.3417
[2025-02-22 16:38:55,236][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:38:55,352][INFO] iter 1000: loss 0.9373
[2025-02-22 16:39:00,482][INFO] iter 1100: loss 0.9186
[2025-02-22 16:39:05,947][INFO] iter 1200: loss 0.9197
[2025-02-22 16:39:11,072][INFO] iter 1300: loss 0.9001
[2025-02-22 16:39:16,465][INFO] iter 1400: loss 0.9332
[2025-02-22 16:39:21,613][INFO] iter 1500: loss 0.9064
[2025-02-22 16:39:26,913][INFO] iter 1600: loss 0.9160
[2025-02-22 16:39:32,167][INFO] iter 1700: loss 0.9131
[2025-02-22 16:39:37,344][INFO] iter 1800: loss 0.9183
[2025-02-22 16:39:42,966][INFO] iter 1900: loss 0.9014
[2025-02-22 16:40:50,735][INFO] step 2000: train loss 0.9148, val loss 1.5524
[2025-02-22 16:40:50,736][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:40:50,865][INFO] iter 2000: loss 0.9123
[2025-02-22 16:40:56,189][INFO] iter 2100: loss 0.9146
[2025-02-22 16:41:01,325][INFO] iter 2200: loss 0.9143
[2025-02-22 16:41:06,904][INFO] iter 2300: loss 0.9262
[2025-02-22 16:41:12,058][INFO] iter 2400: loss 0.9167
[2025-02-22 16:41:17,447][INFO] iter 2500: loss 0.9151
[2025-02-22 16:41:22,629][INFO] iter 2600: loss 0.9280
[2025-02-22 16:41:28,049][INFO] iter 2700: loss 0.9112
[2025-02-22 16:41:33,299][INFO] iter 2800: loss 0.8912
[2025-02-22 16:41:38,512][INFO] iter 2900: loss 0.9004
[2025-02-22 16:42:46,216][INFO] step 3000: train loss 0.9047, val loss 1.4622
[2025-02-22 16:42:46,216][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:42:46,323][INFO] iter 3000: loss 0.9152
[2025-02-22 16:42:51,507][INFO] iter 3100: loss 0.9057
[2025-02-22 16:42:56,902][INFO] iter 3200: loss 0.8952
[2025-02-22 16:43:02,060][INFO] iter 3300: loss 0.9097
[2025-02-22 16:43:07,301][INFO] iter 3400: loss 0.8962
[2025-02-22 16:43:12,482][INFO] iter 3500: loss 0.9058
[2025-02-22 16:43:17,703][INFO] iter 3600: loss 0.9055
[2025-02-22 16:43:22,908][INFO] iter 3700: loss 0.8981
[2025-02-22 16:43:28,301][INFO] iter 3800: loss 0.9145
[2025-02-22 16:43:33,677][INFO] iter 3900: loss 0.9019
[2025-02-22 16:44:42,035][INFO] step 4000: train loss 0.9055, val loss 1.6252
[2025-02-22 16:44:42,036][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:44:42,145][INFO] iter 4000: loss 0.8947
[2025-02-22 16:44:47,325][INFO] iter 4100: loss 0.9164
[2025-02-22 16:44:52,479][INFO] iter 4200: loss 0.8881
[2025-02-22 16:44:57,911][INFO] iter 4300: loss 0.9124
[2025-02-22 16:45:03,170][INFO] iter 4400: loss 0.8956
[2025-02-22 16:45:08,540][INFO] iter 4500: loss 0.9004
[2025-02-22 16:45:13,744][INFO] iter 4600: loss 0.8964
[2025-02-22 16:45:19,026][INFO] iter 4700: loss 0.9032
[2025-02-22 16:45:24,270][INFO] iter 4800: loss 0.9227
[2025-02-22 16:45:29,634][INFO] iter 4900: loss 0.9080
[2025-02-22 16:46:37,540][INFO] step 5000: train loss 0.9019, val loss 1.5737
[2025-02-22 16:46:37,541][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:46:37,652][INFO] iter 5000: loss 0.9118
[2025-02-22 16:46:43,238][INFO] iter 5100: loss 0.9086
[2025-02-22 16:46:48,395][INFO] iter 5200: loss 0.9067
[2025-02-22 16:46:53,562][INFO] iter 5300: loss 0.9052
[2025-02-22 16:46:58,996][INFO] iter 5400: loss 0.9032
[2025-02-22 16:47:04,342][INFO] iter 5500: loss 0.9160
[2025-02-22 16:47:09,826][INFO] iter 5600: loss 0.8876
[2025-02-22 16:47:15,042][INFO] iter 5700: loss 0.8818
[2025-02-22 16:47:20,375][INFO] iter 5800: loss 0.8896
[2025-02-22 16:47:25,737][INFO] iter 5900: loss 0.8981
[2025-02-22 16:48:33,113][INFO] step 6000: train loss 0.8986, val loss 1.6247
[2025-02-22 16:48:33,114][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:48:33,226][INFO] iter 6000: loss 0.8839
[2025-02-22 16:48:38,409][INFO] iter 6100: loss 0.8978
[2025-02-22 16:48:43,815][INFO] iter 6200: loss 0.9073
[2025-02-22 16:48:48,987][INFO] iter 6300: loss 0.9082
[2025-02-22 16:48:54,172][INFO] iter 6400: loss 0.8983
[2025-02-22 16:48:59,715][INFO] iter 6500: loss 0.9076
[2025-02-22 16:49:04,916][INFO] iter 6600: loss 0.9017
[2025-02-22 16:49:10,350][INFO] iter 6700: loss 0.9078
[2025-02-22 16:49:15,566][INFO] iter 6800: loss 0.9123
[2025-02-22 16:49:20,797][INFO] iter 6900: loss 0.8932
[2025-02-22 16:50:27,980][INFO] step 7000: train loss 0.8971, val loss 1.6459
[2025-02-22 16:50:27,980][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:50:28,086][INFO] iter 7000: loss 0.8961
[2025-02-22 16:50:33,301][INFO] iter 7100: loss 0.9073
[2025-02-22 16:50:38,568][INFO] iter 7200: loss 0.8907
[2025-02-22 16:50:43,876][INFO] iter 7300: loss 0.8829
[2025-02-22 16:50:49,118][INFO] iter 7400: loss 0.9112
[2025-02-22 16:50:54,310][INFO] iter 7500: loss 0.9083
[2025-02-22 16:50:59,963][INFO] iter 7600: loss 0.8988
[2025-02-22 16:51:05,185][INFO] iter 7700: loss 0.9005
[2025-02-22 16:51:10,580][INFO] iter 7800: loss 0.8970
[2025-02-22 16:51:15,815][INFO] iter 7900: loss 0.8866
[2025-02-22 16:52:23,046][INFO] step 8000: train loss 0.8961, val loss 1.6840
[2025-02-22 16:52:23,046][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:52:23,156][INFO] iter 8000: loss 0.8760
[2025-02-22 16:52:28,344][INFO] iter 8100: loss 0.9089
[2025-02-22 16:52:33,553][INFO] iter 8200: loss 0.8960
[2025-02-22 16:52:38,724][INFO] iter 8300: loss 0.9011
[2025-02-22 16:52:43,906][INFO] iter 8400: loss 0.8806
[2025-02-22 16:52:49,330][INFO] iter 8500: loss 0.8794
[2025-02-22 16:52:54,543][INFO] iter 8600: loss 0.8986
[2025-02-22 16:53:00,160][INFO] iter 8700: loss 0.8996
[2025-02-22 16:53:05,389][INFO] iter 8800: loss 0.9082
[2025-02-22 16:53:10,824][INFO] iter 8900: loss 0.9057
[2025-02-22 16:54:18,184][INFO] step 9000: train loss 0.8952, val loss 1.6916
[2025-02-22 16:54:18,185][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:54:18,296][INFO] iter 9000: loss 0.9042
[2025-02-22 16:54:23,684][INFO] iter 9100: loss 0.8849
[2025-02-22 16:54:28,846][INFO] iter 9200: loss 0.8870
[2025-02-22 16:54:34,258][INFO] iter 9300: loss 0.8946
[2025-02-22 16:54:39,453][INFO] iter 9400: loss 0.8816
[2025-02-22 16:54:44,657][INFO] iter 9500: loss 0.8849
[2025-02-22 16:54:50,057][INFO] iter 9600: loss 0.8946
[2025-02-22 16:54:55,297][INFO] iter 9700: loss 0.8949
[2025-02-22 16:55:00,646][INFO] iter 9800: loss 0.9140
[2025-02-22 16:55:05,885][INFO] iter 9900: loss 0.9066
[2025-02-22 16:56:13,133][INFO] step 10000: train loss 0.8949, val loss 1.7504
[2025-02-22 16:56:13,134][INFO] saving checkpoint to out/tree_1_1_120_500_tree
[2025-02-22 16:56:13,255][INFO] iter 10000: loss 0.8945
