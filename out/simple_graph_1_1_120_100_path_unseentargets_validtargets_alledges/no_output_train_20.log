[2025-02-22 01:27:12,015][INFO] step 0: train loss 4.6334, val loss 4.6379
[2025-02-22 01:27:15,935][INFO] iter 0: loss 4.6351
[2025-02-22 01:27:20,621][INFO] iter 100: loss 3.6781
[2025-02-22 01:27:25,202][INFO] iter 200: loss 2.2611
[2025-02-22 01:27:30,359][INFO] iter 300: loss 1.3022
[2025-02-22 01:27:35,016][INFO] iter 400: loss 0.8911
[2025-02-22 01:27:39,982][INFO] iter 500: loss 0.7809
[2025-02-22 01:27:44,611][INFO] iter 600: loss 0.7329
[2025-02-22 01:27:49,255][INFO] iter 700: loss 0.7189
[2025-02-22 01:27:54,503][INFO] iter 800: loss 0.6960
[2025-02-22 01:27:59,169][INFO] iter 900: loss 0.7218
[2025-02-22 01:29:03,512][INFO] step 1000: train loss 0.7042, val loss 1.4024
[2025-02-22 01:29:03,513][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:29:03,641][INFO] iter 1000: loss 0.6921
[2025-02-22 01:29:08,375][INFO] iter 1100: loss 0.6944
[2025-02-22 01:29:13,047][INFO] iter 1200: loss 0.6900
[2025-02-22 01:29:18,154][INFO] iter 1300: loss 0.7031
[2025-02-22 01:29:22,839][INFO] iter 1400: loss 0.6883
[2025-02-22 01:29:27,908][INFO] iter 1500: loss 0.6877
[2025-02-22 01:29:32,616][INFO] iter 1600: loss 0.6970
[2025-02-22 01:29:37,339][INFO] iter 1700: loss 0.6894
[2025-02-22 01:29:42,520][INFO] iter 1800: loss 0.6984
[2025-02-22 01:29:47,251][INFO] iter 1900: loss 0.6841
[2025-02-22 01:30:51,645][INFO] step 2000: train loss 0.6874, val loss 1.5082
[2025-02-22 01:30:51,645][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:30:51,774][INFO] iter 2000: loss 0.6984
[2025-02-22 01:30:56,625][INFO] iter 2100: loss 0.6845
[2025-02-22 01:31:01,415][INFO] iter 2200: loss 0.6880
[2025-02-22 01:31:06,412][INFO] iter 2300: loss 0.6816
[2025-02-22 01:31:11,154][INFO] iter 2400: loss 0.6929
[2025-02-22 01:31:15,947][INFO] iter 2500: loss 0.6866
[2025-02-22 01:31:20,957][INFO] iter 2600: loss 0.6816
[2025-02-22 01:31:25,689][INFO] iter 2700: loss 0.6838
[2025-02-22 01:31:30,805][INFO] iter 2800: loss 0.6825
[2025-02-22 01:31:35,595][INFO] iter 2900: loss 0.6754
[2025-02-22 01:32:40,223][INFO] step 3000: train loss 0.6811, val loss 1.5509
[2025-02-22 01:32:40,223][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:32:40,352][INFO] iter 3000: loss 0.6864
[2025-02-22 01:32:45,196][INFO] iter 3100: loss 0.6770
[2025-02-22 01:32:49,941][INFO] iter 3200: loss 0.6743
[2025-02-22 01:32:55,134][INFO] iter 3300: loss 0.6783
[2025-02-22 01:32:59,916][INFO] iter 3400: loss 0.6871
[2025-02-22 01:33:04,704][INFO] iter 3500: loss 0.6863
[2025-02-22 01:33:09,591][INFO] iter 3600: loss 0.6717
[2025-02-22 01:33:14,358][INFO] iter 3700: loss 0.6956
[2025-02-22 01:33:19,453][INFO] iter 3800: loss 0.6865
[2025-02-22 01:33:24,193][INFO] iter 3900: loss 0.6829
[2025-02-22 01:34:28,004][INFO] step 4000: train loss 0.6765, val loss 1.5980
[2025-02-22 01:34:28,005][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:34:28,129][INFO] iter 4000: loss 0.6904
[2025-02-22 01:34:33,076][INFO] iter 4100: loss 0.6739
[2025-02-22 01:34:37,803][INFO] iter 4200: loss 0.6741
[2025-02-22 01:34:42,675][INFO] iter 4300: loss 0.6872
[2025-02-22 01:34:47,431][INFO] iter 4400: loss 0.6717
[2025-02-22 01:34:52,214][INFO] iter 4500: loss 0.6751
[2025-02-22 01:34:57,370][INFO] iter 4600: loss 0.6808
[2025-02-22 01:35:02,220][INFO] iter 4700: loss 0.6799
[2025-02-22 01:35:07,199][INFO] iter 4800: loss 0.6793
[2025-02-22 01:35:11,948][INFO] iter 4900: loss 0.6787
[2025-02-22 01:36:15,730][INFO] step 5000: train loss 0.6720, val loss 1.6381
[2025-02-22 01:36:15,731][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:36:15,857][INFO] iter 5000: loss 0.6764
[2025-02-22 01:36:20,904][INFO] iter 5100: loss 0.6788
[2025-02-22 01:36:25,632][INFO] iter 5200: loss 0.6612
[2025-02-22 01:36:30,602][INFO] iter 5300: loss 0.6747
[2025-02-22 01:36:35,420][INFO] iter 5400: loss 0.6671
[2025-02-22 01:36:40,308][INFO] iter 5500: loss 0.6747
[2025-02-22 01:36:45,163][INFO] iter 5600: loss 0.6748
[2025-02-22 01:36:49,941][INFO] iter 5700: loss 0.6696
[2025-02-22 01:36:55,095][INFO] iter 5800: loss 0.6616
[2025-02-22 01:36:59,841][INFO] iter 5900: loss 0.6597
[2025-02-22 01:38:03,471][INFO] step 6000: train loss 0.6681, val loss 1.6649
[2025-02-22 01:38:03,472][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:38:03,597][INFO] iter 6000: loss 0.6820
[2025-02-22 01:38:08,373][INFO] iter 6100: loss 0.6701
[2025-02-22 01:38:13,096][INFO] iter 6200: loss 0.6692
[2025-02-22 01:38:18,187][INFO] iter 6300: loss 0.6678
[2025-02-22 01:38:22,944][INFO] iter 6400: loss 0.6644
[2025-02-22 01:38:28,038][INFO] iter 6500: loss 0.6649
[2025-02-22 01:38:32,823][INFO] iter 6600: loss 0.6621
[2025-02-22 01:38:37,604][INFO] iter 6700: loss 0.6554
[2025-02-22 01:38:42,826][INFO] iter 6800: loss 0.6593
[2025-02-22 01:38:47,579][INFO] iter 6900: loss 0.6665
[2025-02-22 01:39:51,468][INFO] step 7000: train loss 0.6654, val loss 1.6981
[2025-02-22 01:39:51,469][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:39:51,573][INFO] iter 7000: loss 0.6559
[2025-02-22 01:39:56,319][INFO] iter 7100: loss 0.6626
[2025-02-22 01:40:01,100][INFO] iter 7200: loss 0.6677
[2025-02-22 01:40:06,073][INFO] iter 7300: loss 0.6541
[2025-02-22 01:40:10,827][INFO] iter 7400: loss 0.6611
[2025-02-22 01:40:15,753][INFO] iter 7500: loss 0.6691
[2025-02-22 01:40:20,540][INFO] iter 7600: loss 0.6496
[2025-02-22 01:40:25,318][INFO] iter 7700: loss 0.6572
[2025-02-22 01:40:30,278][INFO] iter 7800: loss 0.6647
[2025-02-22 01:40:35,106][INFO] iter 7900: loss 0.6671
[2025-02-22 01:41:39,303][INFO] step 8000: train loss 0.6622, val loss 1.7279
[2025-02-22 01:41:39,303][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:41:39,408][INFO] iter 8000: loss 0.6549
[2025-02-22 01:41:44,156][INFO] iter 8100: loss 0.6651
[2025-02-22 01:41:48,879][INFO] iter 8200: loss 0.6722
[2025-02-22 01:41:53,890][INFO] iter 8300: loss 0.6541
[2025-02-22 01:41:58,647][INFO] iter 8400: loss 0.6523
[2025-02-22 01:42:03,767][INFO] iter 8500: loss 0.6719
[2025-02-22 01:42:08,584][INFO] iter 8600: loss 0.6553
[2025-02-22 01:42:13,601][INFO] iter 8700: loss 0.6646
[2025-02-22 01:42:18,359][INFO] iter 8800: loss 0.6575
[2025-02-22 01:42:23,108][INFO] iter 8900: loss 0.6582
[2025-02-22 01:43:27,376][INFO] step 9000: train loss 0.6605, val loss 1.7430
[2025-02-22 01:43:27,376][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:43:27,478][INFO] iter 9000: loss 0.6653
[2025-02-22 01:43:32,224][INFO] iter 9100: loss 0.6640
[2025-02-22 01:43:37,063][INFO] iter 9200: loss 0.6654
[2025-02-22 01:43:41,801][INFO] iter 9300: loss 0.6529
[2025-02-22 01:43:46,556][INFO] iter 9400: loss 0.6594
[2025-02-22 01:43:51,600][INFO] iter 9500: loss 0.6670
[2025-02-22 01:43:56,383][INFO] iter 9600: loss 0.6608
[2025-02-22 01:44:01,379][INFO] iter 9700: loss 0.6466
[2025-02-22 01:44:06,135][INFO] iter 9800: loss 0.6642
[2025-02-22 01:44:10,882][INFO] iter 9900: loss 0.6680
[2025-02-22 01:45:15,040][INFO] step 10000: train loss 0.6596, val loss 1.7571
[2025-02-22 01:45:15,041][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-22 01:45:15,144][INFO] iter 10000: loss 0.6511
