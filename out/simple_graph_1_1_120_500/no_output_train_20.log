[2025-02-14 00:09:18,660][INFO] step 0: train loss 6.2480, val loss 6.2486
[2025-02-14 00:09:22,545][INFO] iter 0: loss 6.2540
[2025-02-14 00:09:27,510][INFO] iter 100: loss 5.7229
[2025-02-14 00:09:32,581][INFO] iter 200: loss 4.8058
[2025-02-14 00:09:37,882][INFO] iter 300: loss 3.6897
[2025-02-14 00:09:42,905][INFO] iter 400: loss 2.8031
[2025-02-14 00:09:48,171][INFO] iter 500: loss 2.2640
[2025-02-14 00:09:53,254][INFO] iter 600: loss 1.9504
[2025-02-14 00:09:58,547][INFO] iter 700: loss 1.8276
[2025-02-14 00:10:03,656][INFO] iter 800: loss 1.7949
[2025-02-14 00:10:08,784][INFO] iter 900: loss 1.7272
[2025-02-14 00:11:15,792][INFO] step 1000: train loss 1.6831, val loss 1.6825
[2025-02-14 00:11:15,792][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:11:15,907][INFO] iter 1000: loss 1.6867
[2025-02-14 00:11:21,084][INFO] iter 1100: loss 1.6541
[2025-02-14 00:11:26,668][INFO] iter 1200: loss 1.6496
[2025-02-14 00:11:32,010][INFO] iter 1300: loss 1.5996
[2025-02-14 00:11:37,308][INFO] iter 1400: loss 1.6159
[2025-02-14 00:11:42,490][INFO] iter 1500: loss 1.5964
[2025-02-14 00:11:47,649][INFO] iter 1600: loss 1.5741
[2025-02-14 00:11:52,913][INFO] iter 1700: loss 1.5550
[2025-02-14 00:11:58,040][INFO] iter 1800: loss 1.5917
[2025-02-14 00:12:03,326][INFO] iter 1900: loss 1.5711
[2025-02-14 00:13:10,739][INFO] step 2000: train loss 1.5476, val loss 1.5562
[2025-02-14 00:13:10,739][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:13:10,851][INFO] iter 2000: loss 1.5383
[2025-02-14 00:13:15,974][INFO] iter 2100: loss 1.5601
[2025-02-14 00:13:21,094][INFO] iter 2200: loss 1.5444
[2025-02-14 00:13:26,624][INFO] iter 2300: loss 1.5656
[2025-02-14 00:13:31,792][INFO] iter 2400: loss 1.5229
[2025-02-14 00:13:37,157][INFO] iter 2500: loss 1.5256
[2025-02-14 00:13:42,345][INFO] iter 2600: loss 1.5123
[2025-02-14 00:13:47,512][INFO] iter 2700: loss 1.4958
[2025-02-14 00:13:52,658][INFO] iter 2800: loss 1.4929
[2025-02-14 00:13:57,795][INFO] iter 2900: loss 1.5018
[2025-02-14 00:15:04,385][INFO] step 3000: train loss 1.5066, val loss 1.5244
[2025-02-14 00:15:04,385][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:15:04,495][INFO] iter 3000: loss 1.5082
[2025-02-14 00:15:09,790][INFO] iter 3100: loss 1.5065
[2025-02-14 00:15:14,926][INFO] iter 3200: loss 1.5074
[2025-02-14 00:15:20,091][INFO] iter 3300: loss 1.5002
[2025-02-14 00:15:25,607][INFO] iter 3400: loss 1.4953
[2025-02-14 00:15:30,805][INFO] iter 3500: loss 1.5035
[2025-02-14 00:15:36,164][INFO] iter 3600: loss 1.4995
[2025-02-14 00:15:41,321][INFO] iter 3700: loss 1.4782
[2025-02-14 00:15:46,536][INFO] iter 3800: loss 1.5135
[2025-02-14 00:15:51,659][INFO] iter 3900: loss 1.4895
[2025-02-14 00:16:58,252][INFO] step 4000: train loss 1.4863, val loss 1.5060
[2025-02-14 00:16:58,252][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:16:58,361][INFO] iter 4000: loss 1.4894
[2025-02-14 00:17:03,494][INFO] iter 4100: loss 1.4931
[2025-02-14 00:17:08,710][INFO] iter 4200: loss 1.4693
[2025-02-14 00:17:13,850][INFO] iter 4300: loss 1.4763
[2025-02-14 00:17:19,018][INFO] iter 4400: loss 1.4772
[2025-02-14 00:17:24,352][INFO] iter 4500: loss 1.4714
[2025-02-14 00:17:29,542][INFO] iter 4600: loss 1.4750
[2025-02-14 00:17:34,952][INFO] iter 4700: loss 1.4875
[2025-02-14 00:17:40,106][INFO] iter 4800: loss 1.4779
[2025-02-14 00:17:45,314][INFO] iter 4900: loss 1.4750
[2025-02-14 00:18:51,799][INFO] step 5000: train loss 1.4713, val loss 1.4944
[2025-02-14 00:18:51,799][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:18:51,907][INFO] iter 5000: loss 1.4830
[2025-02-14 00:18:57,065][INFO] iter 5100: loss 1.4834
[2025-02-14 00:19:02,188][INFO] iter 5200: loss 1.4491
[2025-02-14 00:19:07,342][INFO] iter 5300: loss 1.4568
[2025-02-14 00:19:12,514][INFO] iter 5400: loss 1.4719
[2025-02-14 00:19:17,751][INFO] iter 5500: loss 1.4562
[2025-02-14 00:19:23,090][INFO] iter 5600: loss 1.4587
[2025-02-14 00:19:28,253][INFO] iter 5700: loss 1.4524
[2025-02-14 00:19:33,598][INFO] iter 5800: loss 1.4517
[2025-02-14 00:19:38,731][INFO] iter 5900: loss 1.4669
[2025-02-14 00:20:45,321][INFO] step 6000: train loss 1.4611, val loss 1.4826
[2025-02-14 00:20:45,321][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:20:45,432][INFO] iter 6000: loss 1.4518
[2025-02-14 00:20:50,562][INFO] iter 6100: loss 1.4374
[2025-02-14 00:20:55,843][INFO] iter 6200: loss 1.4648
[2025-02-14 00:21:00,982][INFO] iter 6300: loss 1.4650
[2025-02-14 00:21:06,155][INFO] iter 6400: loss 1.4367
[2025-02-14 00:21:11,344][INFO] iter 6500: loss 1.4669
[2025-02-14 00:21:16,659][INFO] iter 6600: loss 1.4421
[2025-02-14 00:21:21,969][INFO] iter 6700: loss 1.4652
[2025-02-14 00:21:27,113][INFO] iter 6800: loss 1.4472
[2025-02-14 00:21:32,453][INFO] iter 6900: loss 1.4679
[2025-02-14 00:22:39,183][INFO] step 7000: train loss 1.4516, val loss 1.4782
[2025-02-14 00:22:39,184][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:22:39,326][INFO] iter 7000: loss 1.4456
[2025-02-14 00:22:44,719][INFO] iter 7100: loss 1.4657
[2025-02-14 00:22:49,867][INFO] iter 7200: loss 1.4502
[2025-02-14 00:22:55,016][INFO] iter 7300: loss 1.4546
[2025-02-14 00:23:00,175][INFO] iter 7400: loss 1.4406
[2025-02-14 00:23:05,355][INFO] iter 7500: loss 1.4618
[2025-02-14 00:23:10,549][INFO] iter 7600: loss 1.4700
[2025-02-14 00:23:15,723][INFO] iter 7700: loss 1.4523
[2025-02-14 00:23:21,007][INFO] iter 7800: loss 1.4499
[2025-02-14 00:23:26,154][INFO] iter 7900: loss 1.4325
[2025-02-14 00:24:32,841][INFO] step 8000: train loss 1.4447, val loss 1.4735
[2025-02-14 00:24:32,842][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:24:32,949][INFO] iter 8000: loss 1.4619
[2025-02-14 00:24:38,085][INFO] iter 8100: loss 1.4545
[2025-02-14 00:24:43,617][INFO] iter 8200: loss 1.4262
[2025-02-14 00:24:48,870][INFO] iter 8300: loss 1.4433
[2025-02-14 00:24:54,043][INFO] iter 8400: loss 1.4633
[2025-02-14 00:24:59,232][INFO] iter 8500: loss 1.4437
[2025-02-14 00:25:04,431][INFO] iter 8600: loss 1.4549
[2025-02-14 00:25:09,641][INFO] iter 8700: loss 1.4444
[2025-02-14 00:25:14,785][INFO] iter 8800: loss 1.4233
[2025-02-14 00:25:20,055][INFO] iter 8900: loss 1.4262
[2025-02-14 00:26:27,219][INFO] step 9000: train loss 1.4408, val loss 1.4675
[2025-02-14 00:26:27,219][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:26:27,330][INFO] iter 9000: loss 1.4311
[2025-02-14 00:26:32,471][INFO] iter 9100: loss 1.4230
[2025-02-14 00:26:37,600][INFO] iter 9200: loss 1.4492
[2025-02-14 00:26:43,009][INFO] iter 9300: loss 1.4323
[2025-02-14 00:26:48,203][INFO] iter 9400: loss 1.4314
[2025-02-14 00:26:53,507][INFO] iter 9500: loss 1.4413
[2025-02-14 00:26:58,684][INFO] iter 9600: loss 1.4469
[2025-02-14 00:27:03,836][INFO] iter 9700: loss 1.4365
[2025-02-14 00:27:09,125][INFO] iter 9800: loss 1.4391
[2025-02-14 00:27:14,329][INFO] iter 9900: loss 1.4423
[2025-02-14 00:28:20,839][INFO] step 10000: train loss 1.4380, val loss 1.4678
[2025-02-14 00:28:20,840][INFO] saving checkpoint to out/simple_graph_1_1_120_500
[2025-02-14 00:28:20,945][INFO] iter 10000: loss 1.4497
