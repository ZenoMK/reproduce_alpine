[2025-02-23 03:03:56,249][INFO] step 0: train loss 4.6370, val loss 4.6371
[2025-02-23 03:04:00,176][INFO] iter 0: loss 4.6373
[2025-02-23 03:04:04,784][INFO] iter 100: loss 3.2582
[2025-02-23 03:04:09,530][INFO] iter 200: loss 1.7846
[2025-02-23 03:04:14,586][INFO] iter 300: loss 0.8778
[2025-02-23 03:04:19,257][INFO] iter 400: loss 0.6293
[2025-02-23 03:04:24,143][INFO] iter 500: loss 0.5720
[2025-02-23 03:04:28,939][INFO] iter 600: loss 0.5615
[2025-02-23 03:04:33,676][INFO] iter 700: loss 0.5660
[2025-02-23 03:04:38,771][INFO] iter 800: loss 0.5584
[2025-02-23 03:04:43,534][INFO] iter 900: loss 0.5551
[2025-02-23 03:05:48,534][INFO] step 1000: train loss 0.5589, val loss 0.5588
[2025-02-23 03:05:48,535][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:05:48,644][INFO] iter 1000: loss 0.5590
[2025-02-23 03:05:53,416][INFO] iter 1100: loss 0.5563
[2025-02-23 03:05:58,170][INFO] iter 1200: loss 0.5533
[2025-02-23 03:06:03,268][INFO] iter 1300: loss 0.5588
[2025-02-23 03:06:08,061][INFO] iter 1400: loss 0.5582
[2025-02-23 03:06:13,069][INFO] iter 1500: loss 0.5554
[2025-02-23 03:06:17,845][INFO] iter 1600: loss 0.5550
[2025-02-23 03:06:22,598][INFO] iter 1700: loss 0.5522
[2025-02-23 03:06:27,628][INFO] iter 1800: loss 0.5579
[2025-02-23 03:06:32,370][INFO] iter 1900: loss 0.5662
[2025-02-23 03:07:37,330][INFO] step 2000: train loss 0.5576, val loss 0.5571
[2025-02-23 03:07:37,331][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:07:37,435][INFO] iter 2000: loss 0.5573
[2025-02-23 03:07:42,183][INFO] iter 2100: loss 0.5589
[2025-02-23 03:07:46,908][INFO] iter 2200: loss 0.5523
[2025-02-23 03:07:52,111][INFO] iter 2300: loss 0.5571
[2025-02-23 03:07:56,875][INFO] iter 2400: loss 0.5635
[2025-02-23 03:08:01,938][INFO] iter 2500: loss 0.5511
[2025-02-23 03:08:06,731][INFO] iter 2600: loss 0.5480
[2025-02-23 03:08:11,622][INFO] iter 2700: loss 0.5532
[2025-02-23 03:08:16,574][INFO] iter 2800: loss 0.5520
[2025-02-23 03:08:21,318][INFO] iter 2900: loss 0.5606
[2025-02-23 03:09:26,336][INFO] step 3000: train loss 0.5563, val loss 0.5565
[2025-02-23 03:09:26,337][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:09:26,442][INFO] iter 3000: loss 0.5525
[2025-02-23 03:09:31,185][INFO] iter 3100: loss 0.5618
[2025-02-23 03:09:35,907][INFO] iter 3200: loss 0.5519
[2025-02-23 03:09:41,004][INFO] iter 3300: loss 0.5540
[2025-02-23 03:09:45,906][INFO] iter 3400: loss 0.5625
[2025-02-23 03:09:50,980][INFO] iter 3500: loss 0.5623
[2025-02-23 03:09:55,768][INFO] iter 3600: loss 0.5530
[2025-02-23 03:10:00,562][INFO] iter 3700: loss 0.5607
[2025-02-23 03:10:05,580][INFO] iter 3800: loss 0.5587
[2025-02-23 03:10:10,325][INFO] iter 3900: loss 0.5549
[2025-02-23 03:11:15,609][INFO] step 4000: train loss 0.5551, val loss 0.5553
[2025-02-23 03:11:15,610][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:11:15,715][INFO] iter 4000: loss 0.5588
[2025-02-23 03:11:20,461][INFO] iter 4100: loss 0.5515
[2025-02-23 03:11:25,310][INFO] iter 4200: loss 0.5557
[2025-02-23 03:11:30,094][INFO] iter 4300: loss 0.5510
[2025-02-23 03:11:34,900][INFO] iter 4400: loss 0.5508
[2025-02-23 03:11:39,926][INFO] iter 4500: loss 0.5600
[2025-02-23 03:11:44,720][INFO] iter 4600: loss 0.5599
[2025-02-23 03:11:49,634][INFO] iter 4700: loss 0.5588
[2025-02-23 03:11:54,412][INFO] iter 4800: loss 0.5582
[2025-02-23 03:11:59,177][INFO] iter 4900: loss 0.5628
[2025-02-23 03:13:04,228][INFO] step 5000: train loss 0.5552, val loss 0.5551
[2025-02-23 03:13:04,228][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:13:04,332][INFO] iter 5000: loss 0.5578
[2025-02-23 03:13:09,161][INFO] iter 5100: loss 0.5629
[2025-02-23 03:13:14,179][INFO] iter 5200: loss 0.5531
[2025-02-23 03:13:18,933][INFO] iter 5300: loss 0.5619
[2025-02-23 03:13:23,698][INFO] iter 5400: loss 0.5592
[2025-02-23 03:13:29,019][INFO] iter 5500: loss 0.5571
[2025-02-23 03:13:33,815][INFO] iter 5600: loss 0.5527
[2025-02-23 03:13:38,818][INFO] iter 5700: loss 0.5507
[2025-02-23 03:13:43,569][INFO] iter 5800: loss 0.5583
[2025-02-23 03:13:48,407][INFO] iter 5900: loss 0.5470
[2025-02-23 03:14:53,339][INFO] step 6000: train loss 0.5548, val loss 0.5548
[2025-02-23 03:14:53,339][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:14:53,441][INFO] iter 6000: loss 0.5519
[2025-02-23 03:14:58,197][INFO] iter 6100: loss 0.5623
[2025-02-23 03:15:03,236][INFO] iter 6200: loss 0.5544
[2025-02-23 03:15:07,982][INFO] iter 6300: loss 0.5511
[2025-02-23 03:15:12,752][INFO] iter 6400: loss 0.5572
[2025-02-23 03:15:18,052][INFO] iter 6500: loss 0.5524
[2025-02-23 03:15:22,837][INFO] iter 6600: loss 0.5506
[2025-02-23 03:15:27,923][INFO] iter 6700: loss 0.5517
[2025-02-23 03:15:32,673][INFO] iter 6800: loss 0.5477
[2025-02-23 03:15:37,435][INFO] iter 6900: loss 0.5523
[2025-02-23 03:16:42,413][INFO] step 7000: train loss 0.5543, val loss 0.5544
[2025-02-23 03:16:42,414][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:16:42,519][INFO] iter 7000: loss 0.5496
[2025-02-23 03:16:47,268][INFO] iter 7100: loss 0.5488
[2025-02-23 03:16:52,258][INFO] iter 7200: loss 0.5528
[2025-02-23 03:16:57,007][INFO] iter 7300: loss 0.5498
[2025-02-23 03:17:01,776][INFO] iter 7400: loss 0.5525
[2025-02-23 03:17:06,897][INFO] iter 7500: loss 0.5450
[2025-02-23 03:17:11,753][INFO] iter 7600: loss 0.5610
[2025-02-23 03:17:16,788][INFO] iter 7700: loss 0.5658
[2025-02-23 03:17:21,539][INFO] iter 7800: loss 0.5546
[2025-02-23 03:17:26,289][INFO] iter 7900: loss 0.5540
[2025-02-23 03:18:31,598][INFO] step 8000: train loss 0.5539, val loss 0.5547
[2025-02-23 03:18:31,598][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:18:31,714][INFO] iter 8000: loss 0.5552
[2025-02-23 03:18:36,463][INFO] iter 8100: loss 0.5576
[2025-02-23 03:18:41,498][INFO] iter 8200: loss 0.5656
[2025-02-23 03:18:46,388][INFO] iter 8300: loss 0.5612
[2025-02-23 03:18:51,152][INFO] iter 8400: loss 0.5502
[2025-02-23 03:18:56,112][INFO] iter 8500: loss 0.5528
[2025-02-23 03:19:00,903][INFO] iter 8600: loss 0.5610
[2025-02-23 03:19:06,046][INFO] iter 8700: loss 0.5568
[2025-02-23 03:19:10,795][INFO] iter 8800: loss 0.5544
[2025-02-23 03:19:15,540][INFO] iter 8900: loss 0.5575
[2025-02-23 03:20:20,566][INFO] step 9000: train loss 0.5540, val loss 0.5546
[2025-02-23 03:20:20,566][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:20:20,671][INFO] iter 9000: loss 0.5531
[2025-02-23 03:20:25,410][INFO] iter 9100: loss 0.5481
[2025-02-23 03:20:30,464][INFO] iter 9200: loss 0.5522
[2025-02-23 03:20:35,245][INFO] iter 9300: loss 0.5629
[2025-02-23 03:20:40,202][INFO] iter 9400: loss 0.5527
[2025-02-23 03:20:45,103][INFO] iter 9500: loss 0.5581
[2025-02-23 03:20:49,890][INFO] iter 9600: loss 0.5551
[2025-02-23 03:20:55,078][INFO] iter 9700: loss 0.5553
[2025-02-23 03:20:59,833][INFO] iter 9800: loss 0.5530
[2025-02-23 03:21:04,804][INFO] iter 9900: loss 0.5587
[2025-02-23 03:22:09,697][INFO] step 10000: train loss 0.5540, val loss 0.5543
[2025-02-23 03:22:09,698][INFO] saving checkpoint to out/tree_1_1_120_100_tree
[2025-02-23 03:22:09,804][INFO] iter 10000: loss 0.5534
