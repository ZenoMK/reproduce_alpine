[2025-02-13 23:31:47,235][INFO] step 0: train loss 4.6477, val loss 4.6540
[2025-02-13 23:31:47,737][INFO] iter 0: loss 4.6470
[2025-02-13 23:31:52,536][INFO] iter 100: loss 3.7677
[2025-02-13 23:31:57,580][INFO] iter 200: loss 2.4652
[2025-02-13 23:32:02,294][INFO] iter 300: loss 1.4503
[2025-02-13 23:32:07,408][INFO] iter 400: loss 1.0168
[2025-02-13 23:32:12,100][INFO] iter 500: loss 0.8703
[2025-02-13 23:32:16,803][INFO] iter 600: loss 0.8423
[2025-02-13 23:32:21,983][INFO] iter 700: loss 0.8063
[2025-02-13 23:32:26,701][INFO] iter 800: loss 0.7906
[2025-02-13 23:32:31,897][INFO] iter 900: loss 0.7829
[2025-02-13 23:33:37,478][INFO] step 1000: train loss 0.7821, val loss 1.2131
[2025-02-13 23:33:37,478][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:33:37,582][INFO] iter 1000: loss 0.7794
[2025-02-13 23:33:42,668][INFO] iter 1100: loss 0.7747
[2025-02-13 23:33:47,343][INFO] iter 1200: loss 0.7727
[2025-02-13 23:33:52,013][INFO] iter 1300: loss 0.7792
[2025-02-13 23:33:57,251][INFO] iter 1400: loss 0.7725
[2025-02-13 23:34:02,106][INFO] iter 1500: loss 0.7760
[2025-02-13 23:34:07,175][INFO] iter 1600: loss 0.7789
[2025-02-13 23:34:11,894][INFO] iter 1700: loss 0.7645
[2025-02-13 23:34:16,692][INFO] iter 1800: loss 0.7489
[2025-02-13 23:34:21,906][INFO] iter 1900: loss 0.7601
[2025-02-13 23:35:27,939][INFO] step 2000: train loss 0.7616, val loss 1.3393
[2025-02-13 23:35:27,940][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:35:28,046][INFO] iter 2000: loss 0.7759
[2025-02-13 23:35:33,042][INFO] iter 2100: loss 0.7575
[2025-02-13 23:35:37,756][INFO] iter 2200: loss 0.7632
[2025-02-13 23:35:42,421][INFO] iter 2300: loss 0.7559
[2025-02-13 23:35:47,327][INFO] iter 2400: loss 0.7488
[2025-02-13 23:35:52,016][INFO] iter 2500: loss 0.7503
[2025-02-13 23:35:57,043][INFO] iter 2600: loss 0.7516
[2025-02-13 23:36:01,770][INFO] iter 2700: loss 0.7505
[2025-02-13 23:36:06,485][INFO] iter 2800: loss 0.7460
[2025-02-13 23:36:11,514][INFO] iter 2900: loss 0.7443
[2025-02-13 23:37:16,446][INFO] step 3000: train loss 0.7526, val loss 1.3958
[2025-02-13 23:37:16,446][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:37:16,548][INFO] iter 3000: loss 0.7521
[2025-02-13 23:37:21,567][INFO] iter 3100: loss 0.7454
[2025-02-13 23:37:26,216][INFO] iter 3200: loss 0.7464
[2025-02-13 23:37:31,231][INFO] iter 3300: loss 0.7466
[2025-02-13 23:37:35,904][INFO] iter 3400: loss 0.7579
[2025-02-13 23:37:40,594][INFO] iter 3500: loss 0.7531
[2025-02-13 23:37:45,851][INFO] iter 3600: loss 0.7438
[2025-02-13 23:37:50,694][INFO] iter 3700: loss 0.7411
[2025-02-13 23:37:55,696][INFO] iter 3800: loss 0.7496
[2025-02-13 23:38:00,396][INFO] iter 3900: loss 0.7446
[2025-02-13 23:39:04,848][INFO] step 4000: train loss 0.7449, val loss 1.4452
[2025-02-13 23:39:04,849][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:39:04,975][INFO] iter 4000: loss 0.7385
[2025-02-13 23:39:09,931][INFO] iter 4100: loss 0.7404
[2025-02-13 23:39:14,580][INFO] iter 4200: loss 0.7367
[2025-02-13 23:39:19,569][INFO] iter 4300: loss 0.7457
[2025-02-13 23:39:24,269][INFO] iter 4400: loss 0.7450
[2025-02-13 23:39:29,130][INFO] iter 4500: loss 0.7418
[2025-02-13 23:39:33,919][INFO] iter 4600: loss 0.7375
[2025-02-13 23:39:38,628][INFO] iter 4700: loss 0.7333
[2025-02-13 23:39:43,727][INFO] iter 4800: loss 0.7355
[2025-02-13 23:39:48,430][INFO] iter 4900: loss 0.7368
[2025-02-13 23:40:53,034][INFO] step 5000: train loss 0.7390, val loss 1.4809
[2025-02-13 23:40:53,035][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:40:53,136][INFO] iter 5000: loss 0.7458
[2025-02-13 23:40:57,808][INFO] iter 5100: loss 0.7488
[2025-02-13 23:41:02,541][INFO] iter 5200: loss 0.7278
[2025-02-13 23:41:07,607][INFO] iter 5300: loss 0.7318
[2025-02-13 23:41:12,283][INFO] iter 5400: loss 0.7335
[2025-02-13 23:41:17,187][INFO] iter 5500: loss 0.7560
[2025-02-13 23:41:21,886][INFO] iter 5600: loss 0.7413
[2025-02-13 23:41:26,601][INFO] iter 5700: loss 0.7303
[2025-02-13 23:41:31,831][INFO] iter 5800: loss 0.7309
[2025-02-13 23:41:36,632][INFO] iter 5900: loss 0.7273
[2025-02-13 23:42:41,468][INFO] step 6000: train loss 0.7329, val loss 1.5102
[2025-02-13 23:42:41,469][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:42:41,571][INFO] iter 6000: loss 0.7478
[2025-02-13 23:42:46,251][INFO] iter 6100: loss 0.7203
[2025-02-13 23:42:50,898][INFO] iter 6200: loss 0.7321
[2025-02-13 23:42:55,858][INFO] iter 6300: loss 0.7136
[2025-02-13 23:43:00,531][INFO] iter 6400: loss 0.7299
[2025-02-13 23:43:05,599][INFO] iter 6500: loss 0.7356
[2025-02-13 23:43:10,301][INFO] iter 6600: loss 0.7415
[2025-02-13 23:43:15,258][INFO] iter 6700: loss 0.7277
[2025-02-13 23:43:19,991][INFO] iter 6800: loss 0.7249
[2025-02-13 23:43:24,696][INFO] iter 6900: loss 0.7322
[2025-02-13 23:44:29,415][INFO] step 7000: train loss 0.7287, val loss 1.5369
[2025-02-13 23:44:29,415][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:44:29,519][INFO] iter 7000: loss 0.7292
[2025-02-13 23:44:34,371][INFO] iter 7100: loss 0.7292
[2025-02-13 23:44:39,326][INFO] iter 7200: loss 0.7274
[2025-02-13 23:44:43,988][INFO] iter 7300: loss 0.7250
[2025-02-13 23:44:48,727][INFO] iter 7400: loss 0.7157
[2025-02-13 23:44:53,755][INFO] iter 7500: loss 0.7227
[2025-02-13 23:44:58,456][INFO] iter 7600: loss 0.7159
[2025-02-13 23:45:03,372][INFO] iter 7700: loss 0.7280
[2025-02-13 23:45:08,081][INFO] iter 7800: loss 0.7282
[2025-02-13 23:45:12,789][INFO] iter 7900: loss 0.7221
[2025-02-13 23:46:17,561][INFO] step 8000: train loss 0.7247, val loss 1.5607
[2025-02-13 23:46:17,561][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:46:17,667][INFO] iter 8000: loss 0.7208
[2025-02-13 23:46:22,347][INFO] iter 8100: loss 0.7266
[2025-02-13 23:46:27,375][INFO] iter 8200: loss 0.7236
[2025-02-13 23:46:32,041][INFO] iter 8300: loss 0.7152
[2025-02-13 23:46:36,717][INFO] iter 8400: loss 0.7240
[2025-02-13 23:46:41,656][INFO] iter 8500: loss 0.7332
[2025-02-13 23:46:46,354][INFO] iter 8600: loss 0.7176
[2025-02-13 23:46:51,420][INFO] iter 8700: loss 0.7219
[2025-02-13 23:46:56,134][INFO] iter 8800: loss 0.7245
[2025-02-13 23:47:01,261][INFO] iter 8900: loss 0.7189
[2025-02-13 23:48:05,766][INFO] step 9000: train loss 0.7228, val loss 1.5846
[2025-02-13 23:48:05,767][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:48:05,870][INFO] iter 9000: loss 0.7158
[2025-02-13 23:48:10,546][INFO] iter 9100: loss 0.7186
[2025-02-13 23:48:15,701][INFO] iter 9200: loss 0.7342
[2025-02-13 23:48:20,482][INFO] iter 9300: loss 0.7202
[2025-02-13 23:48:25,450][INFO] iter 9400: loss 0.7185
[2025-02-13 23:48:30,133][INFO] iter 9500: loss 0.7246
[2025-02-13 23:48:34,958][INFO] iter 9600: loss 0.7180
[2025-02-13 23:48:39,871][INFO] iter 9700: loss 0.7131
[2025-02-13 23:48:44,584][INFO] iter 9800: loss 0.7188
[2025-02-13 23:48:49,590][INFO] iter 9900: loss 0.7180
[2025-02-13 23:49:54,267][INFO] step 10000: train loss 0.7218, val loss 1.5977
[2025-02-13 23:49:54,268][INFO] saving checkpoint to out/simple_graph_1_1_120_100
[2025-02-13 23:49:54,374][INFO] iter 10000: loss 0.7099
