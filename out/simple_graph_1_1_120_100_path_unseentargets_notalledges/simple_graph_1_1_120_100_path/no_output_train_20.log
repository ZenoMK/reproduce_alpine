[2025-02-21 20:47:46,124][INFO] step 0: train loss 4.6477, val loss 4.6113
[2025-02-21 20:47:49,617][INFO] iter 0: loss 4.6469
[2025-02-21 20:47:54,348][INFO] iter 100: loss 3.6940
[2025-02-21 20:47:59,786][INFO] iter 200: loss 2.3147
[2025-02-21 20:48:04,515][INFO] iter 300: loss 1.3059
[2025-02-21 20:48:09,844][INFO] iter 400: loss 0.9264
[2025-02-21 20:48:14,610][INFO] iter 500: loss 0.7997
[2025-02-21 20:48:19,670][INFO] iter 600: loss 0.7761
[2025-02-21 20:48:24,787][INFO] iter 700: loss 0.7356
[2025-02-21 20:48:29,535][INFO] iter 800: loss 0.7482
[2025-02-21 20:48:34,970][INFO] iter 900: loss 0.7413
[2025-02-21 20:49:44,537][INFO] step 1000: train loss 0.7300, val loss 1.3527
[2025-02-21 20:49:44,538][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:49:44,646][INFO] iter 1000: loss 0.7312
[2025-02-21 20:49:50,113][INFO] iter 1100: loss 0.7298
[2025-02-21 20:49:54,899][INFO] iter 1200: loss 0.6981
[2025-02-21 20:50:00,195][INFO] iter 1300: loss 0.7181
[2025-02-21 20:50:04,941][INFO] iter 1400: loss 0.7259
[2025-02-21 20:50:09,697][INFO] iter 1500: loss 0.7178
[2025-02-21 20:50:15,237][INFO] iter 1600: loss 0.7100
[2025-02-21 20:50:20,144][INFO] iter 1700: loss 0.7149
[2025-02-21 20:50:25,494][INFO] iter 1800: loss 0.7114
[2025-02-21 20:50:30,253][INFO] iter 1900: loss 0.7164
[2025-02-21 20:51:39,988][INFO] step 2000: train loss 0.7143, val loss 1.4485
[2025-02-21 20:51:39,989][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:51:40,099][INFO] iter 2000: loss 0.7105
[2025-02-21 20:51:44,848][INFO] iter 2100: loss 0.7196
[2025-02-21 20:51:50,279][INFO] iter 2200: loss 0.7227
[2025-02-21 20:51:55,141][INFO] iter 2300: loss 0.7190
[2025-02-21 20:52:00,034][INFO] iter 2400: loss 0.7087
[2025-02-21 20:52:05,153][INFO] iter 2500: loss 0.7063
[2025-02-21 20:52:09,996][INFO] iter 2600: loss 0.7053
[2025-02-21 20:52:15,479][INFO] iter 2700: loss 0.7079
[2025-02-21 20:52:20,225][INFO] iter 2800: loss 0.7191
[2025-02-21 20:52:25,520][INFO] iter 2900: loss 0.7111
[2025-02-21 20:53:35,297][INFO] step 3000: train loss 0.7091, val loss 1.5009
[2025-02-21 20:53:35,298][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:53:35,409][INFO] iter 3000: loss 0.7016
[2025-02-21 20:53:40,881][INFO] iter 3100: loss 0.6942
[2025-02-21 20:53:45,637][INFO] iter 3200: loss 0.7147
[2025-02-21 20:53:51,024][INFO] iter 3300: loss 0.7067
[2025-02-21 20:53:55,925][INFO] iter 3400: loss 0.7095
[2025-02-21 20:54:00,683][INFO] iter 3500: loss 0.7009
[2025-02-21 20:54:06,165][INFO] iter 3600: loss 0.7100
[2025-02-21 20:54:10,992][INFO] iter 3700: loss 0.7034
[2025-02-21 20:54:16,483][INFO] iter 3800: loss 0.6989
[2025-02-21 20:54:21,210][INFO] iter 3900: loss 0.7077
[2025-02-21 20:55:30,881][INFO] step 4000: train loss 0.7038, val loss 1.5397
[2025-02-21 20:55:30,881][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:55:30,990][INFO] iter 4000: loss 0.7009
[2025-02-21 20:55:35,725][INFO] iter 4100: loss 0.6938
[2025-02-21 20:55:41,033][INFO] iter 4200: loss 0.7069
[2025-02-21 20:55:45,779][INFO] iter 4300: loss 0.6872
[2025-02-21 20:55:50,861][INFO] iter 4400: loss 0.7046
[2025-02-21 20:55:55,831][INFO] iter 4500: loss 0.6888
[2025-02-21 20:56:00,592][INFO] iter 4600: loss 0.7003
[2025-02-21 20:56:05,948][INFO] iter 4700: loss 0.6984
[2025-02-21 20:56:10,775][INFO] iter 4800: loss 0.7076
[2025-02-21 20:56:15,999][INFO] iter 4900: loss 0.6962
[2025-02-21 20:57:24,303][INFO] step 5000: train loss 0.6983, val loss 1.5477
[2025-02-21 20:57:24,303][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:57:24,411][INFO] iter 5000: loss 0.7038
[2025-02-21 20:57:29,737][INFO] iter 5100: loss 0.7008
[2025-02-21 20:57:34,448][INFO] iter 5200: loss 0.6948
[2025-02-21 20:57:39,202][INFO] iter 5300: loss 0.6968
[2025-02-21 20:57:44,301][INFO] iter 5400: loss 0.6961
[2025-02-21 20:57:49,169][INFO] iter 5500: loss 0.6925
[2025-02-21 20:57:54,502][INFO] iter 5600: loss 0.7017
[2025-02-21 20:57:59,254][INFO] iter 5700: loss 0.6948
[2025-02-21 20:58:04,427][INFO] iter 5800: loss 0.6884
[2025-02-21 20:58:09,302][INFO] iter 5900: loss 0.6901
[2025-02-21 20:59:18,014][INFO] step 6000: train loss 0.6952, val loss 1.5768
[2025-02-21 20:59:18,015][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 20:59:18,128][INFO] iter 6000: loss 0.6835
[2025-02-21 20:59:22,900][INFO] iter 6100: loss 0.7042
[2025-02-21 20:59:27,843][INFO] iter 6200: loss 0.6888
[2025-02-21 20:59:32,826][INFO] iter 6300: loss 0.6980
[2025-02-21 20:59:37,578][INFO] iter 6400: loss 0.6891
[2025-02-21 20:59:42,968][INFO] iter 6500: loss 0.6952
[2025-02-21 20:59:47,892][INFO] iter 6600: loss 0.6938
[2025-02-21 20:59:53,100][INFO] iter 6700: loss 0.6918
[2025-02-21 20:59:57,838][INFO] iter 6800: loss 0.7056
[2025-02-21 21:00:02,627][INFO] iter 6900: loss 0.6944
[2025-02-21 21:01:11,687][INFO] step 7000: train loss 0.6912, val loss 1.6037
[2025-02-21 21:01:11,688][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 21:01:11,792][INFO] iter 7000: loss 0.6954
[2025-02-21 21:01:16,750][INFO] iter 7100: loss 0.6828
[2025-02-21 21:01:21,750][INFO] iter 7200: loss 0.6929
[2025-02-21 21:01:26,501][INFO] iter 7300: loss 0.6886
[2025-02-21 21:01:31,844][INFO] iter 7400: loss 0.6906
[2025-02-21 21:01:36,612][INFO] iter 7500: loss 0.6950
[2025-02-21 21:01:42,006][INFO] iter 7600: loss 0.6843
[2025-02-21 21:01:46,757][INFO] iter 7700: loss 0.6982
[2025-02-21 21:01:51,501][INFO] iter 7800: loss 0.6929
[2025-02-21 21:01:56,998][INFO] iter 7900: loss 0.6806
[2025-02-21 21:03:07,151][INFO] step 8000: train loss 0.6889, val loss 1.6177
[2025-02-21 21:03:07,151][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 21:03:07,262][INFO] iter 8000: loss 0.6943
[2025-02-21 21:03:12,044][INFO] iter 8100: loss 0.6948
[2025-02-21 21:03:16,850][INFO] iter 8200: loss 0.6984
[2025-02-21 21:03:22,242][INFO] iter 8300: loss 0.6884
[2025-02-21 21:03:26,992][INFO] iter 8400: loss 0.6807
[2025-02-21 21:03:32,375][INFO] iter 8500: loss 0.6925
[2025-02-21 21:03:37,200][INFO] iter 8600: loss 0.6896
[2025-02-21 21:03:42,515][INFO] iter 8700: loss 0.6919
[2025-02-21 21:03:47,352][INFO] iter 8800: loss 0.6922
[2025-02-21 21:03:52,098][INFO] iter 8900: loss 0.6839
[2025-02-21 21:05:02,409][INFO] step 9000: train loss 0.6868, val loss 1.6333
[2025-02-21 21:05:02,410][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 21:05:02,521][INFO] iter 9000: loss 0.6951
[2025-02-21 21:05:07,837][INFO] iter 9100: loss 0.6795
[2025-02-21 21:05:12,674][INFO] iter 9200: loss 0.6881
[2025-02-21 21:05:17,537][INFO] iter 9300: loss 0.6849
[2025-02-21 21:05:22,980][INFO] iter 9400: loss 0.6862
[2025-02-21 21:05:27,735][INFO] iter 9500: loss 0.6769
[2025-02-21 21:05:33,090][INFO] iter 9600: loss 0.6860
[2025-02-21 21:05:37,933][INFO] iter 9700: loss 0.6825
[2025-02-21 21:05:42,716][INFO] iter 9800: loss 0.6856
[2025-02-21 21:05:47,867][INFO] iter 9900: loss 0.6868
[2025-02-21 21:06:57,579][INFO] step 10000: train loss 0.6864, val loss 1.6434
[2025-02-21 21:06:57,580][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 21:06:57,691][INFO] iter 10000: loss 0.6829
