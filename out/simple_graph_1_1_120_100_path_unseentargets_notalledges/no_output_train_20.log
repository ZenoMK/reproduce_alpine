[2025-02-21 16:25:28,429][INFO] step 0: train loss 4.6449, val loss 4.6688
[2025-02-21 16:25:31,603][INFO] iter 0: loss 4.6439
[2025-02-21 16:25:36,602][INFO] iter 100: loss 3.6160
[2025-02-21 16:25:41,342][INFO] iter 200: loss 2.1558
[2025-02-21 16:25:45,991][INFO] iter 300: loss 1.2207
[2025-02-21 16:25:50,938][INFO] iter 400: loss 0.8597
[2025-02-21 16:25:55,813][INFO] iter 500: loss 0.7720
[2025-02-21 16:26:00,848][INFO] iter 600: loss 0.7348
[2025-02-21 16:26:05,561][INFO] iter 700: loss 0.7195
[2025-02-21 16:26:10,303][INFO] iter 800: loss 0.7056
[2025-02-21 16:26:15,385][INFO] iter 900: loss 0.7048
[2025-02-21 16:27:20,662][INFO] step 1000: train loss 0.6978, val loss 6.2006
[2025-02-21 16:27:20,662][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:27:20,772][INFO] iter 1000: loss 0.6999
[2025-02-21 16:27:25,881][INFO] iter 1100: loss 0.6935
[2025-02-21 16:27:30,697][INFO] iter 1200: loss 0.6948
[2025-02-21 16:27:35,721][INFO] iter 1300: loss 0.6937
[2025-02-21 16:27:40,639][INFO] iter 1400: loss 0.6898
[2025-02-21 16:27:45,460][INFO] iter 1500: loss 0.6828
[2025-02-21 16:27:50,754][INFO] iter 1600: loss 0.6867
[2025-02-21 16:27:55,589][INFO] iter 1700: loss 0.6932
[2025-02-21 16:28:00,695][INFO] iter 1800: loss 0.6940
[2025-02-21 16:28:05,500][INFO] iter 1900: loss 0.6867
[2025-02-21 16:29:11,171][INFO] step 2000: train loss 0.6844, val loss 8.7623
[2025-02-21 16:29:11,172][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:29:11,305][INFO] iter 2000: loss 0.6803
[2025-02-21 16:29:16,326][INFO] iter 2100: loss 0.6883
[2025-02-21 16:29:21,082][INFO] iter 2200: loss 0.6787
[2025-02-21 16:29:26,161][INFO] iter 2300: loss 0.6759
[2025-02-21 16:29:30,949][INFO] iter 2400: loss 0.6868
[2025-02-21 16:29:35,757][INFO] iter 2500: loss 0.6835
[2025-02-21 16:29:40,914][INFO] iter 2600: loss 0.6926
[2025-02-21 16:29:45,823][INFO] iter 2700: loss 0.6764
[2025-02-21 16:29:50,858][INFO] iter 2800: loss 0.6708
[2025-02-21 16:29:55,684][INFO] iter 2900: loss 0.6737
[2025-02-21 16:31:00,873][INFO] step 3000: train loss 0.6761, val loss 9.9892
[2025-02-21 16:31:00,873][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:31:00,974][INFO] iter 3000: loss 0.6821
[2025-02-21 16:31:05,759][INFO] iter 3100: loss 0.6829
[2025-02-21 16:31:10,504][INFO] iter 3200: loss 0.6641
[2025-02-21 16:31:15,803][INFO] iter 3300: loss 0.6767
[2025-02-21 16:31:20,597][INFO] iter 3400: loss 0.6726
[2025-02-21 16:31:25,651][INFO] iter 3500: loss 0.6757
[2025-02-21 16:31:30,477][INFO] iter 3600: loss 0.6771
[2025-02-21 16:31:35,311][INFO] iter 3700: loss 0.6747
[2025-02-21 16:31:40,493][INFO] iter 3800: loss 0.6583
[2025-02-21 16:31:45,315][INFO] iter 3900: loss 0.6674
[2025-02-21 16:32:50,326][INFO] step 4000: train loss 0.6694, val loss 10.5770
[2025-02-21 16:32:50,327][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:32:50,432][INFO] iter 4000: loss 0.6761
[2025-02-21 16:32:55,214][INFO] iter 4100: loss 0.6524
[2025-02-21 16:33:00,295][INFO] iter 4200: loss 0.6635
[2025-02-21 16:33:05,071][INFO] iter 4300: loss 0.6673
[2025-02-21 16:33:10,030][INFO] iter 4400: loss 0.6683
[2025-02-21 16:33:15,139][INFO] iter 4500: loss 0.6710
[2025-02-21 16:33:19,965][INFO] iter 4600: loss 0.6619
[2025-02-21 16:33:25,023][INFO] iter 4700: loss 0.6677
[2025-02-21 16:33:29,907][INFO] iter 4800: loss 0.6622
[2025-02-21 16:33:34,856][INFO] iter 4900: loss 0.6716
[2025-02-21 16:34:39,924][INFO] step 5000: train loss 0.6625, val loss 10.9803
[2025-02-21 16:34:39,925][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:34:40,030][INFO] iter 5000: loss 0.6780
[2025-02-21 16:34:44,993][INFO] iter 5100: loss 0.6692
[2025-02-21 16:34:50,088][INFO] iter 5200: loss 0.6630
[2025-02-21 16:34:54,862][INFO] iter 5300: loss 0.6565
[2025-02-21 16:34:59,849][INFO] iter 5400: loss 0.6600
[2025-02-21 16:35:04,789][INFO] iter 5500: loss 0.6699
[2025-02-21 16:35:09,613][INFO] iter 5600: loss 0.6418
[2025-02-21 16:35:14,641][INFO] iter 5700: loss 0.6431
[2025-02-21 16:35:19,478][INFO] iter 5800: loss 0.6511
[2025-02-21 16:35:24,657][INFO] iter 5900: loss 0.6600
[2025-02-21 16:36:29,669][INFO] step 6000: train loss 0.6576, val loss 11.1689
[2025-02-21 16:36:29,669][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:36:29,771][INFO] iter 6000: loss 0.6626
[2025-02-21 16:36:34,740][INFO] iter 6100: loss 0.6544
[2025-02-21 16:36:39,486][INFO] iter 6200: loss 0.6603
[2025-02-21 16:36:44,267][INFO] iter 6300: loss 0.6559
[2025-02-21 16:36:49,417][INFO] iter 6400: loss 0.6539
[2025-02-21 16:36:54,243][INFO] iter 6500: loss 0.6519
[2025-02-21 16:36:59,234][INFO] iter 6600: loss 0.6649
[2025-02-21 16:37:04,071][INFO] iter 6700: loss 0.6545
[2025-02-21 16:37:08,908][INFO] iter 6800: loss 0.6547
[2025-02-21 16:37:13,968][INFO] iter 6900: loss 0.6495
[2025-02-21 16:38:18,748][INFO] step 7000: train loss 0.6527, val loss 11.2427
[2025-02-21 16:38:18,749][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:38:18,855][INFO] iter 7000: loss 0.6432
[2025-02-21 16:38:24,103][INFO] iter 7100: loss 0.6526
[2025-02-21 16:38:28,970][INFO] iter 7200: loss 0.6645
[2025-02-21 16:38:34,006][INFO] iter 7300: loss 0.6547
[2025-02-21 16:38:38,801][INFO] iter 7400: loss 0.6617
[2025-02-21 16:38:43,616][INFO] iter 7500: loss 0.6429
[2025-02-21 16:38:48,867][INFO] iter 7600: loss 0.6405
[2025-02-21 16:38:53,709][INFO] iter 7700: loss 0.6607
[2025-02-21 16:38:58,822][INFO] iter 7800: loss 0.6665
[2025-02-21 16:39:03,641][INFO] iter 7900: loss 0.6526
[2025-02-21 16:40:09,142][INFO] step 8000: train loss 0.6496, val loss 11.4179
[2025-02-21 16:40:09,143][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:40:09,251][INFO] iter 8000: loss 0.6460
[2025-02-21 16:40:14,044][INFO] iter 8100: loss 0.6465
[2025-02-21 16:40:18,888][INFO] iter 8200: loss 0.6443
[2025-02-21 16:40:23,871][INFO] iter 8300: loss 0.6520
[2025-02-21 16:40:28,672][INFO] iter 8400: loss 0.6404
[2025-02-21 16:40:33,815][INFO] iter 8500: loss 0.6450
[2025-02-21 16:40:38,643][INFO] iter 8600: loss 0.6539
[2025-02-21 16:40:43,922][INFO] iter 8700: loss 0.6381
[2025-02-21 16:40:48,757][INFO] iter 8800: loss 0.6450
[2025-02-21 16:40:53,580][INFO] iter 8900: loss 0.6414
[2025-02-21 16:41:59,079][INFO] step 9000: train loss 0.6471, val loss 11.4779
[2025-02-21 16:41:59,080][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:41:59,187][INFO] iter 9000: loss 0.6485
[2025-02-21 16:42:03,974][INFO] iter 9100: loss 0.6511
[2025-02-21 16:42:09,003][INFO] iter 9200: loss 0.6432
[2025-02-21 16:42:13,824][INFO] iter 9300: loss 0.6424
[2025-02-21 16:42:18,803][INFO] iter 9400: loss 0.6445
[2025-02-21 16:42:23,666][INFO] iter 9500: loss 0.6427
[2025-02-21 16:42:28,493][INFO] iter 9600: loss 0.6488
[2025-02-21 16:42:33,703][INFO] iter 9700: loss 0.6476
[2025-02-21 16:42:38,540][INFO] iter 9800: loss 0.6521
[2025-02-21 16:42:43,602][INFO] iter 9900: loss 0.6511
[2025-02-21 16:43:48,377][INFO] step 10000: train loss 0.6465, val loss 11.5787
[2025-02-21 16:43:48,378][INFO] saving checkpoint to out/simple_graph_1_1_120_100_path
[2025-02-21 16:43:48,482][INFO] iter 10000: loss 0.6475
