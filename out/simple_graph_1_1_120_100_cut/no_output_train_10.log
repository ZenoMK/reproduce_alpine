[2025-02-18 01:11:51,644][INFO] step 0: train loss 4.6992, val loss 4.6829
[2025-02-18 01:11:55,121][INFO] iter 0: loss 4.6983
[2025-02-18 01:11:58,067][INFO] iter 10: loss 4.5788
[2025-02-18 01:12:01,023][INFO] iter 20: loss 4.2582
[2025-02-18 01:12:03,968][INFO] iter 30: loss 3.8525
[2025-02-18 01:12:06,926][INFO] iter 40: loss 3.4339
[2025-02-18 01:12:09,891][INFO] iter 50: loss 3.0645
[2025-02-18 01:12:12,866][INFO] iter 60: loss 2.7222
[2025-02-18 01:12:15,836][INFO] iter 70: loss 2.3805
[2025-02-18 01:12:18,814][INFO] iter 80: loss 2.1145
[2025-02-18 01:12:21,798][INFO] iter 90: loss 1.8855
[2025-02-18 01:12:36,921][INFO] step 100: train loss 1.6720, val loss 1.8132
[2025-02-18 01:12:36,923][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:12:37,237][INFO] iter 100: loss 1.6961
[2025-02-18 01:12:40,247][INFO] iter 110: loss 1.5256
[2025-02-18 01:12:43,262][INFO] iter 120: loss 1.3840
[2025-02-18 01:12:46,285][INFO] iter 130: loss 1.3067
[2025-02-18 01:12:49,320][INFO] iter 140: loss 1.2128
[2025-02-18 01:12:52,358][INFO] iter 150: loss 1.0999
[2025-02-18 01:12:55,403][INFO] iter 160: loss 1.0560
[2025-02-18 01:12:58,451][INFO] iter 170: loss 1.0060
[2025-02-18 01:13:01,494][INFO] iter 180: loss 0.9626
[2025-02-18 01:13:04,549][INFO] iter 190: loss 0.9136
[2025-02-18 01:13:19,974][INFO] step 200: train loss 0.8635, val loss 0.9923
[2025-02-18 01:13:19,975][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:13:20,292][INFO] iter 200: loss 0.8495
[2025-02-18 01:13:23,385][INFO] iter 210: loss 0.8242
[2025-02-18 01:13:26,483][INFO] iter 220: loss 0.7869
[2025-02-18 01:13:29,589][INFO] iter 230: loss 0.7499
[2025-02-18 01:13:32,696][INFO] iter 240: loss 0.7438
[2025-02-18 01:13:35,814][INFO] iter 250: loss 0.7291
[2025-02-18 01:13:38,938][INFO] iter 260: loss 0.6881
[2025-02-18 01:13:42,061][INFO] iter 270: loss 0.6755
[2025-02-18 01:13:45,179][INFO] iter 280: loss 0.6679
[2025-02-18 01:13:48,290][INFO] iter 290: loss 0.6504
[2025-02-18 01:14:03,671][INFO] step 300: train loss 0.6261, val loss 0.8298
[2025-02-18 01:14:03,671][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:14:03,989][INFO] iter 300: loss 0.6373
[2025-02-18 01:14:07,069][INFO] iter 310: loss 0.6236
[2025-02-18 01:14:10,147][INFO] iter 320: loss 0.5992
[2025-02-18 01:14:13,231][INFO] iter 330: loss 0.5739
[2025-02-18 01:14:16,309][INFO] iter 340: loss 0.5939
[2025-02-18 01:14:19,381][INFO] iter 350: loss 0.5772
[2025-02-18 01:14:22,461][INFO] iter 360: loss 0.5450
[2025-02-18 01:14:25,540][INFO] iter 370: loss 0.5432
[2025-02-18 01:14:28,621][INFO] iter 380: loss 0.5468
[2025-02-18 01:14:31,701][INFO] iter 390: loss 0.5194
[2025-02-18 01:14:47,225][INFO] step 400: train loss 0.5141, val loss 0.7960
[2025-02-18 01:14:47,226][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:14:47,546][INFO] iter 400: loss 0.5033
[2025-02-18 01:14:50,636][INFO] iter 410: loss 0.5078
[2025-02-18 01:14:53,731][INFO] iter 420: loss 0.4858
[2025-02-18 01:14:56,829][INFO] iter 430: loss 0.4933
[2025-02-18 01:14:59,919][INFO] iter 440: loss 0.4795
[2025-02-18 01:15:03,013][INFO] iter 450: loss 0.4934
[2025-02-18 01:15:06,109][INFO] iter 460: loss 0.4698
[2025-02-18 01:15:09,297][INFO] iter 470: loss 0.4635
[2025-02-18 01:15:12,392][INFO] iter 480: loss 0.4573
[2025-02-18 01:15:15,480][INFO] iter 490: loss 0.4480
[2025-02-18 01:15:30,900][INFO] step 500: train loss 0.4423, val loss 0.7817
[2025-02-18 01:15:30,900][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:15:31,219][INFO] iter 500: loss 0.4462
[2025-02-18 01:15:34,306][INFO] iter 510: loss 0.4334
[2025-02-18 01:15:37,391][INFO] iter 520: loss 0.4433
[2025-02-18 01:15:40,477][INFO] iter 530: loss 0.4290
[2025-02-18 01:15:43,569][INFO] iter 540: loss 0.4364
[2025-02-18 01:15:46,656][INFO] iter 550: loss 0.4231
[2025-02-18 01:15:49,748][INFO] iter 560: loss 0.4102
[2025-02-18 01:15:52,840][INFO] iter 570: loss 0.4146
[2025-02-18 01:15:55,930][INFO] iter 580: loss 0.4163
[2025-02-18 01:15:59,028][INFO] iter 590: loss 0.4214
[2025-02-18 01:16:14,423][INFO] step 600: train loss 0.3995, val loss 0.8034
[2025-02-18 01:16:14,424][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:16:14,743][INFO] iter 600: loss 0.3982
[2025-02-18 01:16:17,833][INFO] iter 610: loss 0.3902
[2025-02-18 01:16:20,925][INFO] iter 620: loss 0.3868
[2025-02-18 01:16:24,017][INFO] iter 630: loss 0.3885
[2025-02-18 01:16:27,113][INFO] iter 640: loss 0.3848
[2025-02-18 01:16:30,204][INFO] iter 650: loss 0.3844
[2025-02-18 01:16:33,300][INFO] iter 660: loss 0.3845
[2025-02-18 01:16:36,391][INFO] iter 670: loss 0.3739
[2025-02-18 01:16:39,485][INFO] iter 680: loss 0.3816
[2025-02-18 01:16:42,579][INFO] iter 690: loss 0.3750
[2025-02-18 01:16:57,972][INFO] step 700: train loss 0.3671, val loss 0.7989
[2025-02-18 01:16:57,973][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:16:58,289][INFO] iter 700: loss 0.3643
[2025-02-18 01:17:01,377][INFO] iter 710: loss 0.3608
[2025-02-18 01:17:04,466][INFO] iter 720: loss 0.3672
[2025-02-18 01:17:07,552][INFO] iter 730: loss 0.3612
[2025-02-18 01:17:10,643][INFO] iter 740: loss 0.3576
[2025-02-18 01:17:13,730][INFO] iter 750: loss 0.3490
[2025-02-18 01:17:16,824][INFO] iter 760: loss 0.3615
[2025-02-18 01:17:19,920][INFO] iter 770: loss 0.3528
[2025-02-18 01:17:23,009][INFO] iter 780: loss 0.3457
[2025-02-18 01:17:26,272][INFO] iter 790: loss 0.3518
[2025-02-18 01:17:41,693][INFO] step 800: train loss 0.3462, val loss 0.8036
[2025-02-18 01:17:41,694][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:17:42,012][INFO] iter 800: loss 0.3487
[2025-02-18 01:17:45,108][INFO] iter 810: loss 0.3300
[2025-02-18 01:17:48,195][INFO] iter 820: loss 0.3507
[2025-02-18 01:17:51,286][INFO] iter 830: loss 0.3454
[2025-02-18 01:17:54,380][INFO] iter 840: loss 0.3446
[2025-02-18 01:17:57,466][INFO] iter 850: loss 0.3355
[2025-02-18 01:18:00,561][INFO] iter 860: loss 0.3332
[2025-02-18 01:18:03,651][INFO] iter 870: loss 0.3414
[2025-02-18 01:18:06,740][INFO] iter 880: loss 0.3357
[2025-02-18 01:18:09,833][INFO] iter 890: loss 0.3297
[2025-02-18 01:18:25,397][INFO] step 900: train loss 0.3333, val loss 0.8126
[2025-02-18 01:18:25,397][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:18:25,721][INFO] iter 900: loss 0.3538
[2025-02-18 01:18:28,807][INFO] iter 910: loss 0.3362
[2025-02-18 01:18:31,902][INFO] iter 920: loss 0.3322
[2025-02-18 01:18:34,990][INFO] iter 930: loss 0.3349
[2025-02-18 01:18:38,083][INFO] iter 940: loss 0.3109
[2025-02-18 01:18:41,172][INFO] iter 950: loss 0.3146
[2025-02-18 01:18:44,267][INFO] iter 960: loss 0.3185
[2025-02-18 01:18:47,357][INFO] iter 970: loss 0.3289
[2025-02-18 01:18:50,451][INFO] iter 980: loss 0.3195
[2025-02-18 01:18:53,537][INFO] iter 990: loss 0.3187
[2025-02-18 01:19:08,895][INFO] step 1000: train loss 0.3222, val loss 0.7928
[2025-02-18 01:19:08,895][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-18 01:19:09,218][INFO] iter 1000: loss 0.3202
