[2025-02-20 01:48:58,697][INFO] step 0: train loss 4.6893, val loss 4.6791
[2025-02-20 01:49:02,609][INFO] iter 0: loss 4.6892
[2025-02-20 01:50:05,390][INFO] iter 100: loss 3.6122
[2025-02-20 01:51:08,197][INFO] iter 200: loss 2.1315
[2025-02-20 01:52:10,959][INFO] iter 300: loss 1.0790
[2025-02-20 01:53:13,753][INFO] iter 400: loss 0.6877
[2025-02-20 01:54:16,533][INFO] iter 500: loss 0.5309
[2025-02-20 01:55:19,315][INFO] iter 600: loss 0.4423
[2025-02-20 01:56:22,117][INFO] iter 700: loss 0.4051
[2025-02-20 01:57:24,921][INFO] iter 800: loss 0.3443
[2025-02-20 01:58:27,735][INFO] iter 900: loss 0.2993
[2025-02-20 02:03:19,212][INFO] step 1000: train loss 0.2786, val loss 0.4774
[2025-02-20 02:03:19,212][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-20 02:03:19,863][INFO] iter 1000: loss 0.2765
[2025-02-20 02:04:22,592][INFO] iter 1100: loss 0.2519
[2025-02-20 02:05:25,393][INFO] iter 1200: loss 0.2357
[2025-02-20 02:06:28,204][INFO] iter 1300: loss 0.1958
[2025-02-20 02:07:31,018][INFO] iter 1400: loss 0.1916
[2025-02-20 02:08:33,832][INFO] iter 1500: loss 0.1678
[2025-02-20 02:09:36,667][INFO] iter 1600: loss 0.1514
[2025-02-20 02:10:39,480][INFO] iter 1700: loss 0.1385
[2025-02-20 02:11:42,291][INFO] iter 1800: loss 0.1252
[2025-02-20 02:12:45,123][INFO] iter 1900: loss 0.1114
[2025-02-20 02:17:36,228][INFO] step 2000: train loss 0.1026, val loss 0.6054
[2025-02-20 02:17:36,228][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-20 02:17:36,869][INFO] iter 2000: loss 0.1036
[2025-02-20 02:18:39,621][INFO] iter 2100: loss 0.0955
[2025-02-20 02:19:42,447][INFO] iter 2200: loss 0.0899
[2025-02-20 02:20:45,216][INFO] iter 2300: loss 0.0798
[2025-02-20 02:21:48,050][INFO] iter 2400: loss 0.0736
[2025-02-20 02:22:50,817][INFO] iter 2500: loss 0.0700
[2025-02-20 02:23:53,654][INFO] iter 2600: loss 0.0642
[2025-02-20 02:24:56,456][INFO] iter 2700: loss 0.0584
[2025-02-20 02:25:59,290][INFO] iter 2800: loss 0.0584
[2025-02-20 02:27:02,091][INFO] iter 2900: loss 0.0536
[2025-02-20 02:31:54,080][INFO] step 3000: train loss 0.0512, val loss 0.7741
[2025-02-20 02:31:54,081][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-20 02:31:54,724][INFO] iter 3000: loss 0.0543
[2025-02-20 02:32:57,560][INFO] iter 3100: loss 0.0503
[2025-02-20 02:34:00,386][INFO] iter 3200: loss 0.0466
[2025-02-20 02:35:03,218][INFO] iter 3300: loss 0.0459
[2025-02-20 02:36:06,058][INFO] iter 3400: loss 0.0426
[2025-02-20 02:37:08,887][INFO] iter 3500: loss 0.0417
[2025-02-20 02:38:11,703][INFO] iter 3600: loss 0.0403
[2025-02-20 02:39:14,470][INFO] iter 3700: loss 0.0392
[2025-02-20 02:40:17,291][INFO] iter 3800: loss 0.0373
[2025-02-20 02:41:20,075][INFO] iter 3900: loss 0.0378
[2025-02-20 02:46:11,798][INFO] step 4000: train loss 0.0365, val loss 0.9266
[2025-02-20 02:46:11,799][INFO] saving checkpoint to out/simple_graph_1_1_120_100_cut
[2025-02-20 02:46:12,443][INFO] iter 4000: loss 0.0369
[2025-02-20 02:47:15,232][INFO] iter 4100: loss 0.0357
